{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "mnist_X, mnist_y = mnist.train.images, mnist.train.labels\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(mnist_X, mnist_y, test_size=0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    def __init__(self, vis_dim, hid_dim, function=lambda x: x):\n",
    "        self.W = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(vis_dim, hid_dim)).astype('float32'), name='W')\n",
    "        self.a = tf.Variable(np.zeros(vis_dim).astype('float32'), name='a')\n",
    "        self.b = tf.Variable(np.zeros(hid_dim).astype('float32'), name='b')\n",
    "        self.function = function\n",
    "        self.params = [self.W, self.a, self.b]\n",
    "\n",
    "    def encode(self, x):\n",
    "        u = tf.matmul(x, self.W) + self.b\n",
    "        return self.function(u)\n",
    "\n",
    "    def decode(self, x):\n",
    "        u = tf.matmul(x, tf.transpose(self.W)) + self.a\n",
    "        return self.function(u)\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        y = self.encode(x)\n",
    "        return self.decode(y)\n",
    "\n",
    "    def reconst_error(self, x, noise):\n",
    "        tilde_x = x * noise\n",
    "        reconst_x = self.f_prop(tilde_x)\n",
    "        error = -tf.reduce_mean(tf.reduce_sum(x * tf.log(reconst_x) + (1. - x) * tf.log(1. - reconst_x), axis=1))\n",
    "        return error, reconst_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(cost, params, eps=np.float32(0.1)):\n",
    "    g_params = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, g_param in zip(params, g_params):\n",
    "        if g_param != None:\n",
    "            updates.append(param.assign_add(-eps*g_param))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.copy(train_X)\n",
    "\n",
    "model = Autoencoder(X.shape[1], 500, tf.nn.sigmoid)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='x')\n",
    "noise = tf.placeholder(tf.float32, [None, 784], name='noise')\n",
    "\n",
    "cost, reconst_x = model.reconst_error(x, noise)\n",
    "params = model.params\n",
    "updates = sgd(cost, params)\n",
    "train = tf.group(*updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1, ERROR:90.805206\n",
      "EPOCH:2, ERROR:66.593163\n",
      "EPOCH:3, ERROR:61.505047\n",
      "EPOCH:4, ERROR:58.992512\n",
      "EPOCH:5, ERROR:57.510807\n",
      "EPOCH:6, ERROR:56.539131\n",
      "EPOCH:7, ERROR:55.850365\n",
      "EPOCH:8, ERROR:55.332092\n",
      "EPOCH:9, ERROR:54.924938\n",
      "EPOCH:10, ERROR:54.595123\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = X.shape[0]//batch_size\n",
    "\n",
    "corruption_level = np.float32(0.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        X = shuffle(X, random_state=random_state)\n",
    "        err_all = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            _noise = rng.binomial(size=X[start:end].shape, n=1, p=1-corruption_level)\n",
    "            _, err = sess.run([train, cost], feed_dict={x: X[start:end], noise: _noise})\n",
    "            err_all.append(err)\n",
    "        print('EPOCH:%d, ERROR:%lf' % (epoch+1, np.mean(err_all)))\n",
    "\n",
    "    weight_1 = sess.run(tf.transpose(model.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7300ef1a607c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weight_1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABDCAYAAAAlFqMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAN5JREFUeJzt2zFKBEEQQNFp8QhjbN//LDuHMNY7tKHwE2eEZRd8L66g\n+FBZ91hrbfx4efQCz0aQECQECUFCkBAkBAlB4vXK8L7va855p1Xu6ziOr7XW229zl4LMObfb7fb3\nrR5ojPFxZs7JhCAhSAgSgoQgIUgIEoKEICFICBKChCAhSAgSgoQgIUgIEoKEICFICBKChCAhSAgS\ngoQgIUgIEoKEICFICBKChCAhSAgSgoQgIUgIEuPKv90xxue2bace0T+h9zO/IS4F+Q+cTAgSgoQg\nIUgIEoKEICFIfAPWaRon8SuMbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127ce06a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(100):\n",
    "    ax = fig.add_subplot(10, 10, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(weight_1[i].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "app",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-8ce7254ac033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m del [\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: app"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "del [\n",
    "    tf.app,\n",
    "    tf.compat,\n",
    "    tf.contrib,\n",
    "    tf.errors,\n",
    "    tf.gfile,\n",
    "    tf.graph_util,\n",
    "    tf.image,\n",
    "    tf.layers,\n",
    "    tf.logging,\n",
    "    tf.losses,\n",
    "    tf.metrics,\n",
    "    tf.python_io,\n",
    "    tf.resource_loader,\n",
    "    tf.saved_model,\n",
    "    tf.sdca,\n",
    "    tf.sets,\n",
    "    tf.summary,\n",
    "    tf.sysconfig,\n",
    "    tf.test,\n",
    "    tf.train\n",
    "]\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "    mnist_X = np.r_[mnist.train.images, mnist.test.images]\n",
    "    mnist_y = np.r_[mnist.train.labels, mnist.test.labels]\n",
    "    return train_test_split(mnist_X, mnist_y, test_size=0.2, random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "    # validate for small dataset\n",
    "#     train_X_mini = train_X[:100]\n",
    "#     train_y_mini = train_y[:100]\n",
    "    train_X_mini = train_X[:500]\n",
    "    train_y_mini = train_y[:500]\n",
    "    test_X_mini = test_X[:100]\n",
    "    test_y_mini = test_y[:100]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(np.argmax(test_y_mini, 1), pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(np.argmax(test_y, 1), pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52000, 784)\n",
      "(52000, 10)\n",
      "(13000, 784)\n",
      "(13000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def sdg(cost, params, eta=np.float32(0.1)):\n",
    "        g_params = tf.gradients(cost, params)\n",
    "        updates = []\n",
    "        for p, gp in zip(params, g_params):\n",
    "            if gp is not None:\n",
    "                updates.append(p.assign_add(- eta * gp))\n",
    "        return updates\n",
    "\n",
    "    class AutoEncoder:\n",
    "        def __init__(self, vis_dim, hid_dim, W, function=lambda x: tf.nn.sigmoid(x)):\n",
    "            self.W = W\n",
    "            self.a = tf.Variable(tf.zeros(vis_dim), name='a')\n",
    "            self.b = tf.Variable(tf.zeros(hid_dim), name='b')\n",
    "            self.function = function\n",
    "\n",
    "        def encode(self, x):\n",
    "            u = tf.matmul(x, self.W) + self.b\n",
    "            return self.function(u)\n",
    "\n",
    "        def decode(self, x):\n",
    "            return tf.matmul(x, tf.transpose(self.W)) + self.a\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            y = self.encode(x)\n",
    "            return self.decode(y)\n",
    "\n",
    "        def reconst_error(self, x, noise):\n",
    "            tilda_x = x * noise\n",
    "            reconst_x = self.f_prop(tilda_x)\n",
    "            error = - tf.reduce_mean(x * tf.log(reconst_x) + (1. - x) + tf.log(1. - reconst_x))\n",
    "            return reconst_x, error\n",
    "\n",
    "    class FCLayer:\n",
    "        def __init__(self, input_dim, output_dim, layer_name, function=lambda x: tf.nn.sigmoid(x)):\n",
    "            self.layer_name = layer_name\n",
    "            self.input_dim, self.output_dim = input_dim, output_dim\n",
    "            self.function = function\n",
    "\n",
    "            self.W = self.def_weight([input_dim, output_dim])\n",
    "            self.b = self.def_bias(output_dim)\n",
    "            self._params = [self.W, self.b]\n",
    "\n",
    "            self.autoencoder = AutoEncoder(self.input_dim, self.output_dim, self.W, self.function)\n",
    "\n",
    "        @property\n",
    "        def params(self):\n",
    "            return self._params\n",
    "\n",
    "        def f_prop(self, X):\n",
    "            u = tf.matmul(X, self.W) + self.b\n",
    "            return self.function(u)\n",
    "\n",
    "        def def_weight(self, size, name='weight'):\n",
    "            with tf.variable_scope(self.layer_name):\n",
    "                init = tf.truncated_normal(size)\n",
    "                return tf.get_variable(name, initializer=init)\n",
    "\n",
    "        def def_bias(self, size, name='bias'):\n",
    "            with tf.variable_scope(self.layer_name):\n",
    "                return tf.get_variable(name, initializer=tf.zeros(size))\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    INPUT_DIM = 784\n",
    "    layers = [\n",
    "        FCLayer(INPUT_DIM, 200, layer_name='layer_1'),\n",
    "        FCLayer(200, 100, layer_name='layer_2'),\n",
    "        FCLayer(100, 50, layer_name='layer_3'),\n",
    "        FCLayer(50, 10, layer_name='layer_4', function=lambda x: x),\n",
    "    ]\n",
    "\n",
    "    PRETRAIN_EPOCHS = 10\n",
    "    FINE_TUNE_EPOCHS = 300\n",
    "    IMAGE_DIM = 784\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def pre_train(X, noise_rate=0.1):\n",
    "            rns = np.random.RandomState(42)\n",
    "\n",
    "            for layer_num in range(len(layers) - 1):\n",
    "                input_image = tf.placeholder(tf.float32, [None, IMAGE_DIM])\n",
    "                noise = tf.placeholder(tf.float32, [None, IMAGE_DIM])\n",
    "\n",
    "                _input = input_image\n",
    "                print('before', _input.shape)\n",
    "                for j in range(layer_num):\n",
    "                    _input = layers[j].f_prop(_input)\n",
    "                print('after', _input.shape)\n",
    "\n",
    "                _layer = layers[layer_num]\n",
    "                _, cost = _layer.autoencoder.reconst_error(_input, noise)\n",
    "                _updates = sdg(cost, _layer.params)\n",
    "                _pre_train = tf.group(*_updates)\n",
    "\n",
    "                for epoch in range(PRETRAIN_EPOCHS):\n",
    "                    batch_size = 30\n",
    "                    batch_times = X.shape[0] // batch_size\n",
    "                    epoch_err = 0\n",
    "                    for k in range(batch_times):\n",
    "                        start_idx = k * batch_size\n",
    "                        end_idx = (k + 1) * batch_size\n",
    "                        _noise = rns.binomial(size=X[start_idx:end_idx].shape, n=1., p=1 - noise_rate)\n",
    "                        _, c = sess.run([_pre_train, cost],\n",
    "                                        feed_dict={input_image: X[start_idx:end_idx],\n",
    "                                                   noise: _noise})\n",
    "                        epoch_err += c\n",
    "                    print(\"Layer: %d, Epoch: %d --- Error: %f\" % (layer_num, epoch, epoch_err))\n",
    "\n",
    "        def fine_tune(X, y):\n",
    "            input_image = tf.placeholder(tf.float32, [None, IMAGE_DIM])\n",
    "            actual_labels = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            next_input = input_image\n",
    "            params = []\n",
    "            for _layer in layers:\n",
    "                next_input = _layer.f_prop(next_input)\n",
    "                params.extend(_layer.params)\n",
    "\n",
    "            output = next_input\n",
    "            cost = tf.reduce_mean(tf.softmax_cross_entropy_with_logits(labels=actual_labels,\n",
    "                                                                       logits=output))\n",
    "            correnct = tf.equal(tf.argmax(output, axis=1), actual_labels)\n",
    "            accuracy = tf.reduce_sum(tf.cast(correnct, tf.int64)) / input_image.shape[0]\n",
    "            updates = sdg(cost, params)\n",
    "            train = tf.group(*updates)\n",
    "\n",
    "            for epoch in FINE_TUNE_EPOCHS:\n",
    "                train_data_X, validate_data_X, train_data_y, validate_data_y =\\\n",
    "                    train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "                batch_size = 30\n",
    "                batch_times = train_data_X.shape[0] // batch_size\n",
    "                epoch_err = 0\n",
    "                epoch_accuracy = 0\n",
    "\n",
    "                for train_step in range(batch_times):\n",
    "                    start_idx = train_step * batch_size\n",
    "                    end_idx = (train_step + 1) * batch_size\n",
    "                    _, c, a = sess.run([train, cost, accuracy],\n",
    "                                       feed_dict={input_image: train_data_X[start_idx:end_idx],\n",
    "                                                  actual_labels: train_data_y[start_idx:end_idx]})\n",
    "                    epoch_err += c\n",
    "                    epoch_accuracy += a\n",
    "\n",
    "                # Validation\n",
    "                _, test_a = sess.run([train, accuracy], feed_dict={input_image: validate_data_X,\n",
    "                                                                   actual_labels: validate_data_y})\n",
    "                print(\"Epoch %d out of %d: --- Train loss %f --- Train accuracy %f --- Test accuracy %f\"\n",
    "                      % (epoch, FINE_TUNE_EPOCHS, epoch_err, epoch_accuracy / train_step, a))\n",
    "\n",
    "        pre_train(train_X, noise_rate=0.1)\n",
    "        fine_tune(train_X, train_y)\n",
    "\n",
    "        def infer(X):\n",
    "            out = sess.run(output, feed_dict={input_image: test_X})\n",
    "            return tf.argmax(out, axis=1)\n",
    "\n",
    "        infer(test_X)\n",
    "\n",
    "    return pred_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "before (?, 784)\n",
      "after (?, 784)\n",
      "Layer: 0, Epoch: 0 --- Error: nan\n",
      "Layer: 0, Epoch: 1 --- Error: nan\n",
      "Layer: 0, Epoch: 2 --- Error: nan\n",
      "Layer: 0, Epoch: 3 --- Error: nan\n",
      "Layer: 0, Epoch: 4 --- Error: nan\n",
      "Layer: 0, Epoch: 5 --- Error: nan\n",
      "Layer: 0, Epoch: 6 --- Error: nan\n",
      "Layer: 0, Epoch: 7 --- Error: nan\n",
      "Layer: 0, Epoch: 8 --- Error: nan\n",
      "Layer: 0, Epoch: 9 --- Error: nan\n",
      "before (?, 784)\n",
      "after (?, 200)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 200 and 784 for 'mul_3' (op: 'Mul') with input shapes: [?,200], [?,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 200 and 784 for 'mul_3' (op: 'Mul') with input shapes: [?,200], [?,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-44345d7883f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate_homework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-2483b4481579>\u001b[0m in \u001b[0;36mvalidate_homework\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtest_y_mini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhomework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_mini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_mini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X_mini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_mini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-a28d76057be5>\u001b[0m in \u001b[0;36mhomework\u001b[0;34m(train_X, train_y, test_X)\u001b[0m\n\u001b[1;32m    153\u001b[0m                       % (epoch, FINE_TUNE_EPOCHS, epoch_err, epoch_accuracy / train_step, a))\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mpre_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-a28d76057be5>\u001b[0m in \u001b[0;36mpre_train\u001b[0;34m(X, noise_rate)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0m_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconst_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0m_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0m_pre_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-a28d76057be5>\u001b[0m in \u001b[0;36mreconst_error\u001b[0;34m(self, x, noise)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mreconst_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mtilda_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mreconst_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtilda_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconst_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreconst_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    798\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m   \"\"\"\n\u001b[0;32m-> 1625\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 200 and 784 for 'mul_3' (op: 'Mul') with input shapes: [?,200], [?,784]."
     ]
    }
   ],
   "source": [
    "validate_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    def __init__(self, vis_dim, hid_dim, W, function=lambda x: x):\n",
    "        self.W = W\n",
    "        self.a = tf.Variable(np.zeros(vis_dim).astype('float32'), name='a')\n",
    "        self.b = tf.Variable(np.zeros(hid_dim).astype('float32'), name='b')\n",
    "        self.function = function\n",
    "        self.params = [self.W, self.a, self.b]\n",
    "\n",
    "    def encode(self, x):\n",
    "        u = tf.matmul(x, self.W) + self.b\n",
    "        return self.function(u)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        u = tf.matmul(x, tf.transpose(self.W)) + self.a\n",
    "        return self.function(u)\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        y = self.encode(x)\n",
    "        return self.decode(y)\n",
    "\n",
    "    def reconst_error(self, x, noise):\n",
    "        tilde_x = x * noise\n",
    "        reconst_x = self.f_prop(tilde_x)\n",
    "        error = -tf.reduce_mean(tf.reduce_sum(x * tf.log(reconst_x) + (1. - x) * tf.log(1. - reconst_x), axis=1))\n",
    "        return error, reconst_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function):\n",
    "        self.W = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(in_dim, out_dim)).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "        self.ae = Autoencoder(in_dim, out_dim, self.W, self.function)\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        u = tf.matmul(x, self.W) + self.b\n",
    "        self.z = self.function(u)\n",
    "        return self.z\n",
    "\n",
    "    def pretrain(self, x, noise):\n",
    "        cost, reconst_x = self.ae.reconst_error(x, noise)\n",
    "        return cost, reconst_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dense(784, 500, tf.nn.sigmoid),\n",
    "    Dense(500, 500, tf.nn.sigmoid),\n",
    "    Dense(500, 10, tf.nn.softmax)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-8409e01d4360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconst_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sgd' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.copy(train_X)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for l, layer in enumerate(layers[:-1]):\n",
    "    corruption_level = np.float(0.3)\n",
    "    batch_size = 100\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "    n_epochs = 10\n",
    "\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    noise = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cost, reconst_x = layer.pretrain(x, noise)\n",
    "    params = layer.params\n",
    "    train = sgd(cost, params)\n",
    "    encode = layer.f_prop(x)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        X = shuffle(X, random_state=random_state)\n",
    "        err_all = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            _noise = rng.binomial(size=X[start:end].shape, n=1, p=1-corruption_level)\n",
    "            _, err = sess.run([train, cost], feed_dict={x: X[start:end], noise: _noise})\n",
    "            err_all.append(err)\n",
    "        print('Pretraining:: layer: %d, Epoch: %d, Error: %lf' % (l+1, epoch+1, np.mean(err)))\n",
    "    X = sess.run(encode, feed_dict={x: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d64f8e632687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sgd' is not defined"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def f_props(layers, x):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        x = layer.f_prop(x)\n",
    "        params += layer.params\n",
    "    return x, params\n",
    "\n",
    "y, params = f_props(layers, x)\n",
    "\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(t * tf.log(y), 1))\n",
    "updates = sgd(cost, params)\n",
    "\n",
    "train = tf.group(*updates)\n",
    "valid = tf.argmax(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-22b8c1a47379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EPOCH: %i, Validation cost: %.3f Validation F1: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = train_X.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        sess.run(train, feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "    pred_y, valid_cost = sess.run([valid, cost], feed_dict={x: valid_X, t: valid_y})\n",
    "    print('EPOCH: %i, Validation cost: %.3f Validation F1: %.3f' % (epoch + 1, valid_cost, f1_score(np.argmax(valid_y, 1).astype('int32'), pred_y, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "app",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-d367f5ee2da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m del [\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: app"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "del [\n",
    "    tf.app,\n",
    "    tf.compat,\n",
    "    tf.contrib,\n",
    "    tf.errors,\n",
    "    tf.gfile,\n",
    "    tf.graph_util,\n",
    "    tf.image,\n",
    "    tf.layers,\n",
    "    tf.logging,\n",
    "    tf.losses,\n",
    "    tf.metrics,\n",
    "    tf.python_io,\n",
    "    tf.resource_loader,\n",
    "    tf.saved_model,\n",
    "    tf.sdca,\n",
    "    tf.sets,\n",
    "    tf.summary,\n",
    "    tf.sysconfig,\n",
    "    tf.test,\n",
    "    tf.train\n",
    "]\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "    mnist_X = np.r_[mnist.train.images, mnist.test.images]\n",
    "    mnist_y = np.r_[mnist.train.labels, mnist.test.labels]\n",
    "    return train_test_split(mnist_X, mnist_y, test_size=0.2, random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "    # validate for small dataset\n",
    "#     train_X_mini = train_X[:100]\n",
    "#     train_y_mini = train_y[:100]\n",
    "    train_X_mini = train_X[:10000]\n",
    "    train_y_mini = train_y[:10000]\n",
    "    test_X_mini = test_X[:100]\n",
    "    test_y_mini = test_y[:100]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(np.argmax(test_y_mini, 1), pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(np.argmax(test_y, 1), pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    def sdg(cost, params, eta=np.float32(0.1)):\n",
    "        g_params = tf.gradients(cost, params)\n",
    "        updates = []\n",
    "        for p, gp in zip(params, g_params):\n",
    "            if gp is not None:\n",
    "                updates.append(p.assign_add(- eta * gp))\n",
    "        return updates\n",
    "\n",
    "    class AutoEncoder:\n",
    "        def __init__(self, vis_dim, hid_dim, W, function=lambda x: x):\n",
    "            self.W = W\n",
    "            self.a = tf.Variable(tf.zeros(vis_dim), name='a')\n",
    "            self.b = tf.Variable(tf.zeros(hid_dim), name='b')\n",
    "            self.function = function\n",
    "\n",
    "        def encode(self, x):\n",
    "            u = tf.matmul(x, self.W) + self.b\n",
    "            return self.function(u)\n",
    "\n",
    "        def decode(self, x):\n",
    "            u = tf.matmul(x, tf.transpose(self.W)) + self.a\n",
    "            return self.function(u)\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            y = self.encode(x)\n",
    "            return self.decode(y)\n",
    "\n",
    "        def reconst_error(self, x, noise):\n",
    "            tilde_x = x * noise\n",
    "            reconst_x = self.f_prop(tilde_x)\n",
    "            error = -tf.reduce_mean(\n",
    "                tf.reduce_sum(x * tf.log(reconst_x) + (1. - x) * tf.log(1. - reconst_x), axis=1))\n",
    "            return reconst_x, error\n",
    "\n",
    "    class FCLayer:\n",
    "        def __init__(self, input_dim, output_dim, layer_name, function=tf.nn.sigmoid):\n",
    "            self.layer_name = layer_name\n",
    "            self.input_dim, self.output_dim = input_dim, output_dim\n",
    "            self.function = function\n",
    "\n",
    "            self.W = tf.Variable(\n",
    "                tf.truncated_normal([self.input_dim, self.output_dim], stddev=0.08), name='weight')\n",
    "            self.b = tf.Variable(tf.zeros(self.output_dim), name='bias')\n",
    "            self._params = [self.W, self.b]\n",
    "\n",
    "            self.autoencoder = AutoEncoder(self.input_dim, self.output_dim, self.W, self.function)\n",
    "\n",
    "        @property\n",
    "        def params(self):\n",
    "            return self._params\n",
    "\n",
    "        def f_prop(self, X):\n",
    "            u = tf.matmul(X, self.W) + self.b\n",
    "            return self.function(u)\n",
    "\n",
    "        def def_weight(self, size, name='weight'):\n",
    "            with tf.variable_scope(self.layer_name):\n",
    "                init = tf.truncated_normal(size)\n",
    "                return tf.get_variable(name, initializer=init)\n",
    "\n",
    "        def def_bias(self, size, name='bias'):\n",
    "            with tf.variable_scope(self.layer_name):\n",
    "                return tf.get_variable(name, initializer=tf.zeros(size))\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    INPUT_DIM = 784\n",
    "    layers = [\n",
    "        FCLayer(INPUT_DIM, 500, layer_name='layer_1', function=tf.sigmoid),\n",
    "        FCLayer(500, 200, layer_name='layer_2', function=tf.sigmoid),\n",
    "        FCLayer(200, 80, layer_name='layer_3', function=tf.sigmoid),\n",
    "        FCLayer(80, 10, layer_name='layer_4', function=lambda x: x),\n",
    "    ]\n",
    "\n",
    "    PRETRAIN_EPOCHS = 500\n",
    "    FINE_TUNE_EPOCHS = 1000\n",
    "    IMAGE_DIM = 784\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def pre_train(X, noise_rate=0.1):\n",
    "            rns = np.random.RandomState(42)\n",
    "\n",
    "            for layer_num, _layer in enumerate(layers[:-1]):\n",
    "                _input = tf.placeholder(tf.float32, [None, _layer.input_dim])\n",
    "                noise = tf.placeholder(tf.float32, [None, _layer.input_dim])\n",
    "\n",
    "                _, cost = _layer.autoencoder.reconst_error(_input, noise)\n",
    "                _updates = sdg(cost, _layer.params)\n",
    "                pre_train = tf.group(*_updates)\n",
    "                encode = _layer.f_prop(_input)\n",
    "\n",
    "                for epoch in range(PRETRAIN_EPOCHS):\n",
    "                    batch_size = 60\n",
    "                    batch_times = X.shape[0] // batch_size\n",
    "                    epoch_err = 0\n",
    "                    for k in range(batch_times):\n",
    "                        start_idx = k * batch_size\n",
    "                        end_idx = (k + 1) * batch_size\n",
    "                        _noise = rns.binomial(size=X[start_idx:end_idx].shape, n=1, p=1 - noise_rate)\n",
    "                        _, c = sess.run([pre_train, cost],\n",
    "                                        feed_dict={_input: X[start_idx:end_idx],\n",
    "                                                   noise: _noise})\n",
    "                        epoch_err += c\n",
    "                    print(\"Layer: %d, Epoch: %d --- Error: %f\" % (layer_num + 1, epoch + 1,\n",
    "                                                                  epoch_err))\n",
    "\n",
    "                X = sess.run(encode, feed_dict={_input: X})\n",
    "\n",
    "        # Network flow\n",
    "        input_image = tf.placeholder(tf.float32, [None, IMAGE_DIM])\n",
    "        labels = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "        next_input = input_image\n",
    "        params = []\n",
    "        for _layer in layers:\n",
    "            next_input = _layer.f_prop(next_input)\n",
    "            params.extend(_layer.params)\n",
    "\n",
    "        output = next_input\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                      logits=output))\n",
    "        predicted = tf.argmax(output, axis=1)\n",
    "        _labels = tf.argmax(labels, axis=1)\n",
    "        correct = tf.cast(tf.equal(predicted, _labels), tf.float32)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, _labels), tf.float32))\n",
    "        updates = sdg(cost, params)\n",
    "        train = tf.group(*updates)\n",
    "\n",
    "        def fine_tune(X, y):\n",
    "            for epoch in range(FINE_TUNE_EPOCHS):\n",
    "                train_data_X, validate_data_X, train_data_y, validate_data_y =\\\n",
    "                    train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "                batch_size = 30\n",
    "                batch_times = train_data_X.shape[0] // batch_size\n",
    "                epoch_err = 0\n",
    "                epoch_accuracy = 0\n",
    "\n",
    "                for train_step in range(batch_times):\n",
    "                    start_idx = train_step * batch_size\n",
    "                    end_idx = (train_step + 1) * batch_size\n",
    "                    _, c, a = sess.run([train, cost, accuracy],\n",
    "                                       feed_dict={input_image: train_data_X[start_idx:end_idx],\n",
    "                                                  labels: train_data_y[start_idx:end_idx]})\n",
    "                    epoch_err += c\n",
    "                    epoch_accuracy += a\n",
    "\n",
    "                # Validation\n",
    "                p = sess.run(predicted, feed_dict={input_image: validate_data_X})\n",
    "                print(\"Epoch %d out of %d: --- Train loss %f --- Train accuracy %f --- valid f_score %f\"\n",
    "                      % (epoch, FINE_TUNE_EPOCHS, epoch_err, epoch_accuracy / batch_times,\n",
    "                         f1_score(np.argmax(validate_data_y, axis=1), p, average='macro')))\n",
    "\n",
    "        pre_train(train_X, noise_rate=0.3)\n",
    "        fine_tune(train_X, train_y)\n",
    "\n",
    "        def infer(X):\n",
    "            return sess.run(predicted, feed_dict={input_image: X})\n",
    "\n",
    "        pred_y = infer(test_X)\n",
    "\n",
    "    return pred_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Layer: 1, Epoch: 1 --- Error: 578.365417\n",
      "Layer: 1, Epoch: 2 --- Error: 225.824570\n",
      "Layer: 1, Epoch: 3 --- Error: 194.267365\n",
      "Layer: 1, Epoch: 4 --- Error: 180.777405\n",
      "Layer: 1, Epoch: 5 --- Error: 174.501221\n",
      "Layer: 1, Epoch: 6 --- Error: 169.872162\n",
      "Layer: 1, Epoch: 7 --- Error: 166.153000\n",
      "Layer: 1, Epoch: 8 --- Error: 162.667480\n",
      "Layer: 1, Epoch: 9 --- Error: 159.833054\n",
      "Layer: 1, Epoch: 10 --- Error: 156.132263\n",
      "Layer: 1, Epoch: 11 --- Error: 153.073502\n",
      "Layer: 1, Epoch: 12 --- Error: 149.554337\n",
      "Layer: 1, Epoch: 13 --- Error: 147.089569\n",
      "Layer: 1, Epoch: 14 --- Error: 143.801270\n",
      "Layer: 1, Epoch: 15 --- Error: 142.506805\n",
      "Layer: 1, Epoch: 16 --- Error: 139.035416\n",
      "Layer: 1, Epoch: 17 --- Error: 137.756012\n",
      "Layer: 1, Epoch: 18 --- Error: 133.956390\n",
      "Layer: 1, Epoch: 19 --- Error: 132.134399\n",
      "Layer: 1, Epoch: 20 --- Error: 129.076294\n",
      "Layer: 1, Epoch: 21 --- Error: 127.406754\n",
      "Layer: 1, Epoch: 22 --- Error: 125.234238\n",
      "Layer: 1, Epoch: 23 --- Error: 122.721214\n",
      "Layer: 1, Epoch: 24 --- Error: 120.309929\n",
      "Layer: 1, Epoch: 25 --- Error: 119.110466\n",
      "Layer: 1, Epoch: 26 --- Error: 116.924515\n",
      "Layer: 1, Epoch: 27 --- Error: 115.006493\n",
      "Layer: 1, Epoch: 28 --- Error: 113.221146\n",
      "Layer: 1, Epoch: 29 --- Error: 111.470444\n",
      "Layer: 1, Epoch: 30 --- Error: 110.066818\n",
      "Layer: 1, Epoch: 31 --- Error: 109.250526\n",
      "Layer: 1, Epoch: 32 --- Error: 108.364693\n",
      "Layer: 1, Epoch: 33 --- Error: 107.348007\n",
      "Layer: 1, Epoch: 34 --- Error: 106.125237\n",
      "Layer: 1, Epoch: 35 --- Error: 104.745003\n",
      "Layer: 1, Epoch: 36 --- Error: 103.040703\n",
      "Layer: 1, Epoch: 37 --- Error: 102.710274\n",
      "Layer: 1, Epoch: 38 --- Error: 101.996490\n",
      "Layer: 1, Epoch: 39 --- Error: 101.277443\n",
      "Layer: 1, Epoch: 40 --- Error: 99.518265\n",
      "Layer: 1, Epoch: 41 --- Error: 99.100258\n",
      "Layer: 1, Epoch: 42 --- Error: 98.496933\n",
      "Layer: 1, Epoch: 43 --- Error: 97.690155\n",
      "Layer: 1, Epoch: 44 --- Error: 96.181412\n",
      "Layer: 1, Epoch: 45 --- Error: 95.846336\n",
      "Layer: 1, Epoch: 46 --- Error: 94.679192\n",
      "Layer: 1, Epoch: 47 --- Error: 94.428780\n",
      "Layer: 1, Epoch: 48 --- Error: 93.788216\n",
      "Layer: 1, Epoch: 49 --- Error: 93.097702\n",
      "Layer: 1, Epoch: 50 --- Error: 92.209091\n",
      "Layer: 1, Epoch: 51 --- Error: 92.007286\n",
      "Layer: 1, Epoch: 52 --- Error: 90.992332\n",
      "Layer: 1, Epoch: 53 --- Error: 91.031364\n",
      "Layer: 1, Epoch: 54 --- Error: 89.440742\n",
      "Layer: 1, Epoch: 55 --- Error: 89.082085\n",
      "Layer: 1, Epoch: 56 --- Error: 88.206390\n",
      "Layer: 1, Epoch: 57 --- Error: 87.877106\n",
      "Layer: 1, Epoch: 58 --- Error: 87.090553\n",
      "Layer: 1, Epoch: 59 --- Error: 87.379929\n",
      "Layer: 1, Epoch: 60 --- Error: 86.849831\n",
      "Layer: 1, Epoch: 61 --- Error: 86.114395\n",
      "Layer: 1, Epoch: 62 --- Error: 84.646584\n",
      "Layer: 1, Epoch: 63 --- Error: 84.878708\n",
      "Layer: 1, Epoch: 64 --- Error: 83.977570\n",
      "Layer: 1, Epoch: 65 --- Error: 84.295799\n",
      "Layer: 1, Epoch: 66 --- Error: 84.373131\n",
      "Layer: 1, Epoch: 67 --- Error: 82.919807\n",
      "Layer: 1, Epoch: 68 --- Error: 83.340324\n",
      "Layer: 1, Epoch: 69 --- Error: 82.564949\n",
      "Layer: 1, Epoch: 70 --- Error: 81.427284\n",
      "Layer: 1, Epoch: 71 --- Error: 81.239243\n",
      "Layer: 1, Epoch: 72 --- Error: 81.967812\n",
      "Layer: 1, Epoch: 73 --- Error: 80.942123\n",
      "Layer: 1, Epoch: 74 --- Error: 80.595436\n",
      "Layer: 1, Epoch: 75 --- Error: 79.282242\n",
      "Layer: 1, Epoch: 76 --- Error: 80.478294\n",
      "Layer: 1, Epoch: 77 --- Error: 79.868538\n",
      "Layer: 1, Epoch: 78 --- Error: 79.410934\n",
      "Layer: 1, Epoch: 79 --- Error: 78.948875\n",
      "Layer: 1, Epoch: 80 --- Error: 78.504288\n",
      "Layer: 1, Epoch: 81 --- Error: 77.690056\n",
      "Layer: 1, Epoch: 82 --- Error: 77.813011\n",
      "Layer: 1, Epoch: 83 --- Error: 77.054298\n",
      "Layer: 1, Epoch: 84 --- Error: 77.213615\n",
      "Layer: 1, Epoch: 85 --- Error: 77.012329\n",
      "Layer: 1, Epoch: 86 --- Error: 76.184601\n",
      "Layer: 1, Epoch: 87 --- Error: 76.043747\n",
      "Layer: 1, Epoch: 88 --- Error: 76.247704\n",
      "Layer: 1, Epoch: 89 --- Error: 75.428062\n",
      "Layer: 1, Epoch: 90 --- Error: 75.410362\n",
      "Layer: 1, Epoch: 91 --- Error: 75.439987\n",
      "Layer: 1, Epoch: 92 --- Error: 74.922752\n",
      "Layer: 1, Epoch: 93 --- Error: 74.493568\n",
      "Layer: 1, Epoch: 94 --- Error: 73.661858\n",
      "Layer: 1, Epoch: 95 --- Error: 73.634514\n",
      "Layer: 1, Epoch: 96 --- Error: 73.676048\n",
      "Layer: 1, Epoch: 97 --- Error: 73.902206\n",
      "Layer: 1, Epoch: 98 --- Error: 73.532837\n",
      "Layer: 1, Epoch: 99 --- Error: 73.094040\n",
      "Layer: 1, Epoch: 100 --- Error: 72.942734\n",
      "Layer: 1, Epoch: 101 --- Error: 72.734383\n",
      "Layer: 1, Epoch: 102 --- Error: 72.255302\n",
      "Layer: 1, Epoch: 103 --- Error: 71.789627\n",
      "Layer: 1, Epoch: 104 --- Error: 71.680061\n",
      "Layer: 1, Epoch: 105 --- Error: 71.987572\n",
      "Layer: 1, Epoch: 106 --- Error: 71.432175\n",
      "Layer: 1, Epoch: 107 --- Error: 71.616905\n",
      "Layer: 1, Epoch: 108 --- Error: 70.836411\n",
      "Layer: 1, Epoch: 109 --- Error: 71.137253\n",
      "Layer: 1, Epoch: 110 --- Error: 71.013176\n",
      "Layer: 1, Epoch: 111 --- Error: 70.732811\n",
      "Layer: 1, Epoch: 112 --- Error: 70.220131\n",
      "Layer: 1, Epoch: 113 --- Error: 70.678856\n",
      "Layer: 1, Epoch: 114 --- Error: 70.042313\n",
      "Layer: 1, Epoch: 115 --- Error: 69.853882\n",
      "Layer: 1, Epoch: 116 --- Error: 70.043488\n",
      "Layer: 1, Epoch: 117 --- Error: 69.213486\n",
      "Layer: 1, Epoch: 118 --- Error: 69.476761\n",
      "Layer: 1, Epoch: 119 --- Error: 68.981209\n",
      "Layer: 1, Epoch: 120 --- Error: 69.273140\n",
      "Layer: 1, Epoch: 121 --- Error: 68.811661\n",
      "Layer: 1, Epoch: 122 --- Error: 68.075653\n",
      "Layer: 1, Epoch: 123 --- Error: 68.310883\n",
      "Layer: 1, Epoch: 124 --- Error: 68.412796\n",
      "Layer: 1, Epoch: 125 --- Error: 68.152031\n",
      "Layer: 1, Epoch: 126 --- Error: 67.373390\n",
      "Layer: 1, Epoch: 127 --- Error: 67.423203\n",
      "Layer: 1, Epoch: 128 --- Error: 68.057419\n",
      "Layer: 1, Epoch: 129 --- Error: 67.942932\n",
      "Layer: 1, Epoch: 130 --- Error: 66.843987\n",
      "Layer: 1, Epoch: 131 --- Error: 67.068146\n",
      "Layer: 1, Epoch: 132 --- Error: 67.165428\n",
      "Layer: 1, Epoch: 133 --- Error: 67.144310\n",
      "Layer: 1, Epoch: 134 --- Error: 67.363838\n",
      "Layer: 1, Epoch: 135 --- Error: 66.632095\n",
      "Layer: 1, Epoch: 136 --- Error: 66.234627\n",
      "Layer: 1, Epoch: 137 --- Error: 66.350868\n",
      "Layer: 1, Epoch: 138 --- Error: 66.065186\n",
      "Layer: 1, Epoch: 139 --- Error: 66.135338\n",
      "Layer: 1, Epoch: 140 --- Error: 66.032051\n",
      "Layer: 1, Epoch: 141 --- Error: 66.045334\n",
      "Layer: 1, Epoch: 142 --- Error: 65.151314\n",
      "Layer: 1, Epoch: 143 --- Error: 65.536423\n",
      "Layer: 1, Epoch: 144 --- Error: 65.795143\n",
      "Layer: 1, Epoch: 145 --- Error: 65.329117\n",
      "Layer: 1, Epoch: 146 --- Error: 65.259468\n",
      "Layer: 1, Epoch: 147 --- Error: 65.346634\n",
      "Layer: 1, Epoch: 148 --- Error: 65.032539\n",
      "Layer: 1, Epoch: 149 --- Error: 65.258186\n",
      "Layer: 1, Epoch: 150 --- Error: 65.000053\n",
      "Layer: 1, Epoch: 151 --- Error: 64.869644\n",
      "Layer: 1, Epoch: 152 --- Error: 64.467247\n",
      "Layer: 1, Epoch: 153 --- Error: 63.877254\n",
      "Layer: 1, Epoch: 154 --- Error: 64.264511\n",
      "Layer: 1, Epoch: 155 --- Error: 64.104713\n",
      "Layer: 1, Epoch: 156 --- Error: 64.236328\n",
      "Layer: 1, Epoch: 157 --- Error: 64.461861\n",
      "Layer: 1, Epoch: 158 --- Error: 64.289658\n",
      "Layer: 1, Epoch: 159 --- Error: 63.869404\n",
      "Layer: 1, Epoch: 160 --- Error: 63.915482\n",
      "Layer: 1, Epoch: 161 --- Error: 63.353306\n",
      "Layer: 1, Epoch: 162 --- Error: 64.024704\n",
      "Layer: 1, Epoch: 163 --- Error: 63.816841\n",
      "Layer: 1, Epoch: 164 --- Error: 64.079903\n",
      "Layer: 1, Epoch: 165 --- Error: 62.876266\n",
      "Layer: 1, Epoch: 166 --- Error: 62.949741\n",
      "Layer: 1, Epoch: 167 --- Error: 62.893120\n",
      "Layer: 1, Epoch: 168 --- Error: 62.914696\n",
      "Layer: 1, Epoch: 169 --- Error: 62.930546\n",
      "Layer: 1, Epoch: 170 --- Error: 62.990273\n",
      "Layer: 1, Epoch: 171 --- Error: 62.899731\n",
      "Layer: 1, Epoch: 172 --- Error: 62.692097\n",
      "Layer: 1, Epoch: 173 --- Error: 62.804981\n",
      "Layer: 1, Epoch: 174 --- Error: 62.592659\n",
      "Layer: 1, Epoch: 175 --- Error: 62.220352\n",
      "Layer: 1, Epoch: 176 --- Error: 62.571835\n",
      "Layer: 1, Epoch: 177 --- Error: 61.836338\n",
      "Layer: 1, Epoch: 178 --- Error: 62.153400\n",
      "Layer: 1, Epoch: 179 --- Error: 62.139256\n",
      "Layer: 1, Epoch: 180 --- Error: 62.717655\n",
      "Layer: 1, Epoch: 181 --- Error: 61.330151\n",
      "Layer: 1, Epoch: 182 --- Error: 61.889149\n",
      "Layer: 1, Epoch: 183 --- Error: 61.263935\n",
      "Layer: 1, Epoch: 184 --- Error: 61.770237\n",
      "Layer: 1, Epoch: 185 --- Error: 61.808895\n",
      "Layer: 1, Epoch: 186 --- Error: 61.312401\n",
      "Layer: 1, Epoch: 187 --- Error: 61.729973\n",
      "Layer: 1, Epoch: 188 --- Error: 61.351185\n",
      "Layer: 1, Epoch: 189 --- Error: 61.407890\n",
      "Layer: 1, Epoch: 190 --- Error: 61.353256\n",
      "Layer: 1, Epoch: 191 --- Error: 61.547905\n",
      "Layer: 1, Epoch: 192 --- Error: 61.468136\n",
      "Layer: 1, Epoch: 193 --- Error: 60.996876\n",
      "Layer: 1, Epoch: 194 --- Error: 60.898918\n",
      "Layer: 1, Epoch: 195 --- Error: 60.896706\n",
      "Layer: 1, Epoch: 196 --- Error: 60.669888\n",
      "Layer: 1, Epoch: 197 --- Error: 60.772327\n",
      "Layer: 1, Epoch: 198 --- Error: 61.022827\n",
      "Layer: 1, Epoch: 199 --- Error: 60.658726\n",
      "Layer: 1, Epoch: 200 --- Error: 60.566643\n",
      "Layer: 1, Epoch: 201 --- Error: 60.375481\n",
      "Layer: 1, Epoch: 202 --- Error: 61.032719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1, Epoch: 203 --- Error: 60.385044\n",
      "Layer: 1, Epoch: 204 --- Error: 60.456551\n",
      "Layer: 1, Epoch: 205 --- Error: 60.302322\n",
      "Layer: 1, Epoch: 206 --- Error: 60.635429\n",
      "Layer: 1, Epoch: 207 --- Error: 59.981819\n",
      "Layer: 1, Epoch: 208 --- Error: 60.304577\n",
      "Layer: 1, Epoch: 209 --- Error: 60.002808\n",
      "Layer: 1, Epoch: 210 --- Error: 60.134705\n",
      "Layer: 1, Epoch: 211 --- Error: 59.971298\n",
      "Layer: 1, Epoch: 212 --- Error: 59.932636\n",
      "Layer: 1, Epoch: 213 --- Error: 59.407948\n",
      "Layer: 1, Epoch: 214 --- Error: 59.728703\n",
      "Layer: 1, Epoch: 215 --- Error: 59.597546\n",
      "Layer: 1, Epoch: 216 --- Error: 59.961571\n",
      "Layer: 1, Epoch: 217 --- Error: 59.607967\n",
      "Layer: 1, Epoch: 218 --- Error: 59.566822\n",
      "Layer: 1, Epoch: 219 --- Error: 59.687405\n",
      "Layer: 1, Epoch: 220 --- Error: 60.177498\n",
      "Layer: 1, Epoch: 221 --- Error: 59.264904\n",
      "Layer: 1, Epoch: 222 --- Error: 59.139809\n",
      "Layer: 1, Epoch: 223 --- Error: 59.165592\n",
      "Layer: 1, Epoch: 224 --- Error: 60.037613\n",
      "Layer: 1, Epoch: 225 --- Error: 59.452690\n",
      "Layer: 1, Epoch: 226 --- Error: 59.266243\n",
      "Layer: 1, Epoch: 227 --- Error: 59.186440\n",
      "Layer: 1, Epoch: 228 --- Error: 58.787800\n",
      "Layer: 1, Epoch: 229 --- Error: 59.419292\n",
      "Layer: 1, Epoch: 230 --- Error: 59.111328\n",
      "Layer: 1, Epoch: 231 --- Error: 59.369205\n",
      "Layer: 1, Epoch: 232 --- Error: 59.667362\n",
      "Layer: 1, Epoch: 233 --- Error: 59.004391\n",
      "Layer: 1, Epoch: 234 --- Error: 58.609753\n",
      "Layer: 1, Epoch: 235 --- Error: 59.529736\n",
      "Layer: 1, Epoch: 236 --- Error: 58.647602\n",
      "Layer: 1, Epoch: 237 --- Error: 58.543430\n",
      "Layer: 1, Epoch: 238 --- Error: 58.317631\n",
      "Layer: 1, Epoch: 239 --- Error: 58.660995\n",
      "Layer: 1, Epoch: 240 --- Error: 58.689369\n",
      "Layer: 1, Epoch: 241 --- Error: 59.139046\n",
      "Layer: 1, Epoch: 242 --- Error: 58.152542\n",
      "Layer: 1, Epoch: 243 --- Error: 58.867481\n",
      "Layer: 1, Epoch: 244 --- Error: 58.391068\n",
      "Layer: 1, Epoch: 245 --- Error: 58.065933\n",
      "Layer: 1, Epoch: 246 --- Error: 58.268269\n",
      "Layer: 1, Epoch: 247 --- Error: 58.660110\n",
      "Layer: 1, Epoch: 248 --- Error: 58.450241\n",
      "Layer: 1, Epoch: 249 --- Error: 58.134472\n",
      "Layer: 1, Epoch: 250 --- Error: 58.491749\n",
      "Layer: 1, Epoch: 251 --- Error: 58.044018\n",
      "Layer: 1, Epoch: 252 --- Error: 58.001354\n",
      "Layer: 1, Epoch: 253 --- Error: 58.093700\n",
      "Layer: 1, Epoch: 254 --- Error: 57.727600\n",
      "Layer: 1, Epoch: 255 --- Error: 58.106663\n",
      "Layer: 1, Epoch: 256 --- Error: 57.927223\n",
      "Layer: 1, Epoch: 257 --- Error: 57.745525\n",
      "Layer: 1, Epoch: 258 --- Error: 57.240112\n",
      "Layer: 1, Epoch: 259 --- Error: 58.248493\n",
      "Layer: 1, Epoch: 260 --- Error: 57.555580\n",
      "Layer: 1, Epoch: 261 --- Error: 57.560623\n",
      "Layer: 1, Epoch: 262 --- Error: 57.673588\n",
      "Layer: 1, Epoch: 263 --- Error: 58.209183\n",
      "Layer: 1, Epoch: 264 --- Error: 57.641823\n",
      "Layer: 1, Epoch: 265 --- Error: 56.703484\n",
      "Layer: 1, Epoch: 266 --- Error: 57.702164\n",
      "Layer: 1, Epoch: 267 --- Error: 57.535255\n",
      "Layer: 1, Epoch: 268 --- Error: 57.994709\n",
      "Layer: 1, Epoch: 269 --- Error: 57.628090\n",
      "Layer: 1, Epoch: 270 --- Error: 57.537540\n",
      "Layer: 1, Epoch: 271 --- Error: 57.543190\n",
      "Layer: 1, Epoch: 272 --- Error: 57.339176\n",
      "Layer: 1, Epoch: 273 --- Error: 57.313477\n",
      "Layer: 1, Epoch: 274 --- Error: 57.302517\n",
      "Layer: 1, Epoch: 275 --- Error: 56.786114\n",
      "Layer: 1, Epoch: 276 --- Error: 57.176884\n",
      "Layer: 1, Epoch: 277 --- Error: 57.391903\n",
      "Layer: 1, Epoch: 278 --- Error: 56.606712\n",
      "Layer: 1, Epoch: 279 --- Error: 57.360294\n",
      "Layer: 1, Epoch: 280 --- Error: 56.900192\n",
      "Layer: 1, Epoch: 281 --- Error: 57.227863\n",
      "Layer: 1, Epoch: 282 --- Error: 56.983738\n",
      "Layer: 1, Epoch: 283 --- Error: 56.791679\n",
      "Layer: 1, Epoch: 284 --- Error: 57.127346\n",
      "Layer: 1, Epoch: 285 --- Error: 56.986225\n",
      "Layer: 1, Epoch: 286 --- Error: 57.066994\n",
      "Layer: 1, Epoch: 287 --- Error: 57.300194\n",
      "Layer: 1, Epoch: 288 --- Error: 56.440273\n",
      "Layer: 1, Epoch: 289 --- Error: 56.171280\n",
      "Layer: 1, Epoch: 290 --- Error: 57.052067\n",
      "Layer: 1, Epoch: 291 --- Error: 56.816372\n",
      "Layer: 1, Epoch: 292 --- Error: 57.048374\n",
      "Layer: 1, Epoch: 293 --- Error: 56.864136\n",
      "Layer: 1, Epoch: 294 --- Error: 56.588356\n",
      "Layer: 1, Epoch: 295 --- Error: 57.444981\n",
      "Layer: 1, Epoch: 296 --- Error: 56.641762\n",
      "Layer: 1, Epoch: 297 --- Error: 56.263287\n",
      "Layer: 1, Epoch: 298 --- Error: 56.429462\n",
      "Layer: 1, Epoch: 299 --- Error: 56.337704\n",
      "Layer: 1, Epoch: 300 --- Error: 56.316799\n",
      "Layer: 1, Epoch: 301 --- Error: 56.616287\n",
      "Layer: 1, Epoch: 302 --- Error: 55.972206\n",
      "Layer: 1, Epoch: 303 --- Error: 56.275650\n",
      "Layer: 1, Epoch: 304 --- Error: 56.137489\n",
      "Layer: 1, Epoch: 305 --- Error: 56.276463\n",
      "Layer: 1, Epoch: 306 --- Error: 56.564400\n",
      "Layer: 1, Epoch: 307 --- Error: 56.345566\n",
      "Layer: 1, Epoch: 308 --- Error: 56.387558\n",
      "Layer: 1, Epoch: 309 --- Error: 56.115498\n",
      "Layer: 1, Epoch: 310 --- Error: 56.444149\n",
      "Layer: 1, Epoch: 311 --- Error: 55.958698\n",
      "Layer: 1, Epoch: 312 --- Error: 56.117565\n",
      "Layer: 1, Epoch: 313 --- Error: 56.424812\n",
      "Layer: 1, Epoch: 314 --- Error: 55.787838\n",
      "Layer: 1, Epoch: 315 --- Error: 56.048550\n",
      "Layer: 1, Epoch: 316 --- Error: 56.018200\n",
      "Layer: 1, Epoch: 317 --- Error: 55.579441\n",
      "Layer: 1, Epoch: 318 --- Error: 55.713158\n",
      "Layer: 1, Epoch: 319 --- Error: 56.313152\n",
      "Layer: 1, Epoch: 320 --- Error: 56.171249\n",
      "Layer: 1, Epoch: 321 --- Error: 55.359081\n",
      "Layer: 1, Epoch: 322 --- Error: 56.172329\n",
      "Layer: 1, Epoch: 323 --- Error: 55.474926\n",
      "Layer: 1, Epoch: 324 --- Error: 56.118649\n",
      "Layer: 1, Epoch: 325 --- Error: 55.608418\n",
      "Layer: 1, Epoch: 326 --- Error: 55.876442\n",
      "Layer: 1, Epoch: 327 --- Error: 55.518314\n",
      "Layer: 1, Epoch: 328 --- Error: 56.473034\n",
      "Layer: 1, Epoch: 329 --- Error: 55.523266\n",
      "Layer: 1, Epoch: 330 --- Error: 55.670963\n",
      "Layer: 1, Epoch: 331 --- Error: 55.444847\n",
      "Layer: 1, Epoch: 332 --- Error: 55.567471\n",
      "Layer: 1, Epoch: 333 --- Error: 56.179081\n",
      "Layer: 1, Epoch: 334 --- Error: 55.919964\n",
      "Layer: 1, Epoch: 335 --- Error: 55.233013\n",
      "Layer: 1, Epoch: 336 --- Error: 55.983471\n",
      "Layer: 1, Epoch: 337 --- Error: 55.526688\n",
      "Layer: 1, Epoch: 338 --- Error: 55.884056\n",
      "Layer: 1, Epoch: 339 --- Error: 55.720028\n",
      "Layer: 1, Epoch: 340 --- Error: 56.071987\n",
      "Layer: 1, Epoch: 341 --- Error: 55.098572\n",
      "Layer: 1, Epoch: 342 --- Error: 55.857594\n",
      "Layer: 1, Epoch: 343 --- Error: 55.505398\n",
      "Layer: 1, Epoch: 344 --- Error: 56.165764\n",
      "Layer: 1, Epoch: 345 --- Error: 55.924324\n",
      "Layer: 1, Epoch: 346 --- Error: 55.220249\n",
      "Layer: 1, Epoch: 347 --- Error: 55.322231\n",
      "Layer: 1, Epoch: 348 --- Error: 55.159359\n",
      "Layer: 1, Epoch: 349 --- Error: 54.894596\n",
      "Layer: 1, Epoch: 350 --- Error: 54.988274\n",
      "Layer: 1, Epoch: 351 --- Error: 55.466328\n",
      "Layer: 1, Epoch: 352 --- Error: 56.130821\n",
      "Layer: 1, Epoch: 353 --- Error: 55.172070\n",
      "Layer: 1, Epoch: 354 --- Error: 55.253654\n",
      "Layer: 1, Epoch: 355 --- Error: 55.344006\n",
      "Layer: 1, Epoch: 356 --- Error: 54.825890\n",
      "Layer: 1, Epoch: 357 --- Error: 55.372513\n",
      "Layer: 1, Epoch: 358 --- Error: 55.585056\n",
      "Layer: 1, Epoch: 359 --- Error: 55.460129\n",
      "Layer: 1, Epoch: 360 --- Error: 55.654488\n",
      "Layer: 1, Epoch: 361 --- Error: 55.340328\n",
      "Layer: 1, Epoch: 362 --- Error: 54.688461\n",
      "Layer: 1, Epoch: 363 --- Error: 55.039959\n",
      "Layer: 1, Epoch: 364 --- Error: 55.031475\n",
      "Layer: 1, Epoch: 365 --- Error: 54.916039\n",
      "Layer: 1, Epoch: 366 --- Error: 54.896744\n",
      "Layer: 1, Epoch: 367 --- Error: 55.185265\n",
      "Layer: 1, Epoch: 368 --- Error: 54.920849\n",
      "Layer: 1, Epoch: 369 --- Error: 54.719624\n",
      "Layer: 1, Epoch: 370 --- Error: 54.493305\n",
      "Layer: 1, Epoch: 371 --- Error: 55.310566\n",
      "Layer: 1, Epoch: 372 --- Error: 55.267712\n",
      "Layer: 1, Epoch: 373 --- Error: 55.007969\n",
      "Layer: 1, Epoch: 374 --- Error: 54.633884\n",
      "Layer: 1, Epoch: 375 --- Error: 54.583378\n",
      "Layer: 1, Epoch: 376 --- Error: 54.765602\n",
      "Layer: 1, Epoch: 377 --- Error: 54.793148\n",
      "Layer: 1, Epoch: 378 --- Error: 54.430786\n",
      "Layer: 1, Epoch: 379 --- Error: 54.217472\n",
      "Layer: 1, Epoch: 380 --- Error: 54.331394\n",
      "Layer: 1, Epoch: 381 --- Error: 54.783588\n",
      "Layer: 1, Epoch: 382 --- Error: 54.369228\n",
      "Layer: 1, Epoch: 383 --- Error: 54.541733\n",
      "Layer: 1, Epoch: 384 --- Error: 54.577702\n",
      "Layer: 1, Epoch: 385 --- Error: 54.546379\n",
      "Layer: 1, Epoch: 386 --- Error: 54.720047\n",
      "Layer: 1, Epoch: 387 --- Error: 54.367504\n",
      "Layer: 1, Epoch: 388 --- Error: 54.677254\n",
      "Layer: 1, Epoch: 389 --- Error: 54.274273\n",
      "Layer: 1, Epoch: 390 --- Error: 54.426846\n",
      "Layer: 1, Epoch: 391 --- Error: 54.605442\n",
      "Layer: 1, Epoch: 392 --- Error: 54.311619\n",
      "Layer: 1, Epoch: 393 --- Error: 54.515877\n",
      "Layer: 1, Epoch: 394 --- Error: 54.721035\n",
      "Layer: 1, Epoch: 395 --- Error: 54.470604\n",
      "Layer: 1, Epoch: 396 --- Error: 54.432880\n",
      "Layer: 1, Epoch: 397 --- Error: 54.370869\n",
      "Layer: 1, Epoch: 398 --- Error: 54.705738\n",
      "Layer: 1, Epoch: 399 --- Error: 54.356625\n",
      "Layer: 1, Epoch: 400 --- Error: 54.262024\n",
      "Layer: 1, Epoch: 401 --- Error: 54.242500\n",
      "Layer: 1, Epoch: 402 --- Error: 54.657520\n",
      "Layer: 1, Epoch: 403 --- Error: 54.177513\n",
      "Layer: 1, Epoch: 404 --- Error: 53.959499\n",
      "Layer: 1, Epoch: 405 --- Error: 54.049965\n",
      "Layer: 1, Epoch: 406 --- Error: 54.464897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1, Epoch: 407 --- Error: 54.106251\n",
      "Layer: 1, Epoch: 408 --- Error: 54.152134\n",
      "Layer: 1, Epoch: 409 --- Error: 54.211742\n",
      "Layer: 1, Epoch: 410 --- Error: 54.034893\n",
      "Layer: 1, Epoch: 411 --- Error: 54.545105\n",
      "Layer: 1, Epoch: 412 --- Error: 53.867065\n",
      "Layer: 1, Epoch: 413 --- Error: 53.999798\n",
      "Layer: 1, Epoch: 414 --- Error: 54.231510\n",
      "Layer: 1, Epoch: 415 --- Error: 53.726601\n",
      "Layer: 1, Epoch: 416 --- Error: 53.846184\n",
      "Layer: 1, Epoch: 417 --- Error: 54.040443\n",
      "Layer: 1, Epoch: 418 --- Error: 54.200352\n",
      "Layer: 1, Epoch: 419 --- Error: 54.552509\n",
      "Layer: 1, Epoch: 420 --- Error: 54.391609\n",
      "Layer: 1, Epoch: 421 --- Error: 53.769028\n",
      "Layer: 1, Epoch: 422 --- Error: 54.071461\n",
      "Layer: 1, Epoch: 423 --- Error: 53.536442\n",
      "Layer: 1, Epoch: 424 --- Error: 53.764725\n",
      "Layer: 1, Epoch: 425 --- Error: 53.928455\n",
      "Layer: 1, Epoch: 426 --- Error: 54.175972\n",
      "Layer: 1, Epoch: 427 --- Error: 53.731579\n",
      "Layer: 1, Epoch: 428 --- Error: 53.780357\n",
      "Layer: 1, Epoch: 429 --- Error: 53.916164\n",
      "Layer: 1, Epoch: 430 --- Error: 54.653622\n",
      "Layer: 1, Epoch: 431 --- Error: 54.036251\n",
      "Layer: 1, Epoch: 432 --- Error: 53.349781\n",
      "Layer: 1, Epoch: 433 --- Error: 53.538612\n",
      "Layer: 1, Epoch: 434 --- Error: 54.097500\n",
      "Layer: 1, Epoch: 435 --- Error: 53.748116\n",
      "Layer: 1, Epoch: 436 --- Error: 53.852158\n",
      "Layer: 1, Epoch: 437 --- Error: 53.952564\n",
      "Layer: 1, Epoch: 438 --- Error: 53.719994\n",
      "Layer: 1, Epoch: 439 --- Error: 53.665276\n",
      "Layer: 1, Epoch: 440 --- Error: 53.866524\n",
      "Layer: 1, Epoch: 441 --- Error: 53.609615\n",
      "Layer: 1, Epoch: 442 --- Error: 53.703136\n",
      "Layer: 1, Epoch: 443 --- Error: 53.989567\n",
      "Layer: 1, Epoch: 444 --- Error: 53.758354\n",
      "Layer: 1, Epoch: 445 --- Error: 53.712692\n",
      "Layer: 1, Epoch: 446 --- Error: 53.491356\n",
      "Layer: 1, Epoch: 447 --- Error: 54.460270\n",
      "Layer: 1, Epoch: 448 --- Error: 54.081501\n",
      "Layer: 1, Epoch: 449 --- Error: 53.468681\n",
      "Layer: 1, Epoch: 450 --- Error: 53.976242\n",
      "Layer: 1, Epoch: 451 --- Error: 53.333889\n",
      "Layer: 1, Epoch: 452 --- Error: 53.431862\n",
      "Layer: 1, Epoch: 453 --- Error: 53.722916\n",
      "Layer: 1, Epoch: 454 --- Error: 53.905659\n",
      "Layer: 1, Epoch: 455 --- Error: 53.968216\n",
      "Layer: 1, Epoch: 456 --- Error: 53.583984\n",
      "Layer: 1, Epoch: 457 --- Error: 54.196552\n",
      "Layer: 1, Epoch: 458 --- Error: 54.041565\n",
      "Layer: 1, Epoch: 459 --- Error: 53.322834\n",
      "Layer: 1, Epoch: 460 --- Error: 53.474583\n",
      "Layer: 1, Epoch: 461 --- Error: 53.566296\n",
      "Layer: 1, Epoch: 462 --- Error: 53.813210\n",
      "Layer: 1, Epoch: 463 --- Error: 53.488789\n",
      "Layer: 1, Epoch: 464 --- Error: 53.738914\n",
      "Layer: 1, Epoch: 465 --- Error: 53.106571\n",
      "Layer: 1, Epoch: 466 --- Error: 53.802319\n",
      "Layer: 1, Epoch: 467 --- Error: 53.646362\n",
      "Layer: 1, Epoch: 468 --- Error: 53.622734\n",
      "Layer: 1, Epoch: 469 --- Error: 53.677082\n",
      "Layer: 1, Epoch: 470 --- Error: 53.364853\n",
      "Layer: 1, Epoch: 471 --- Error: 54.188725\n",
      "Layer: 1, Epoch: 472 --- Error: 53.983299\n",
      "Layer: 1, Epoch: 473 --- Error: 53.408726\n",
      "Layer: 1, Epoch: 474 --- Error: 52.996017\n",
      "Layer: 1, Epoch: 475 --- Error: 52.970940\n",
      "Layer: 1, Epoch: 476 --- Error: 53.587334\n",
      "Layer: 1, Epoch: 477 --- Error: 53.377659\n",
      "Layer: 1, Epoch: 478 --- Error: 53.264973\n",
      "Layer: 1, Epoch: 479 --- Error: 53.641235\n",
      "Layer: 1, Epoch: 480 --- Error: 52.919609\n",
      "Layer: 1, Epoch: 481 --- Error: 53.499207\n",
      "Layer: 1, Epoch: 482 --- Error: 53.194569\n",
      "Layer: 1, Epoch: 483 --- Error: 52.931747\n",
      "Layer: 1, Epoch: 484 --- Error: 52.979534\n",
      "Layer: 1, Epoch: 485 --- Error: 53.463428\n",
      "Layer: 1, Epoch: 486 --- Error: 53.175270\n",
      "Layer: 1, Epoch: 487 --- Error: 53.908043\n",
      "Layer: 1, Epoch: 488 --- Error: 53.380638\n",
      "Layer: 1, Epoch: 489 --- Error: 52.781914\n",
      "Layer: 1, Epoch: 490 --- Error: 53.766365\n",
      "Layer: 1, Epoch: 491 --- Error: 52.870258\n",
      "Layer: 1, Epoch: 492 --- Error: 53.175980\n",
      "Layer: 1, Epoch: 493 --- Error: 53.573521\n",
      "Layer: 1, Epoch: 494 --- Error: 53.339237\n",
      "Layer: 1, Epoch: 495 --- Error: 53.086533\n",
      "Layer: 1, Epoch: 496 --- Error: 53.204529\n",
      "Layer: 1, Epoch: 497 --- Error: 53.625401\n",
      "Layer: 1, Epoch: 498 --- Error: 53.247131\n",
      "Layer: 1, Epoch: 499 --- Error: 52.799866\n",
      "Layer: 1, Epoch: 500 --- Error: 53.393204\n",
      "Layer: 2, Epoch: 1 --- Error: 356.903778\n",
      "Layer: 2, Epoch: 2 --- Error: 283.254608\n",
      "Layer: 2, Epoch: 3 --- Error: 276.591125\n",
      "Layer: 2, Epoch: 4 --- Error: 273.982300\n",
      "Layer: 2, Epoch: 5 --- Error: 271.608582\n",
      "Layer: 2, Epoch: 6 --- Error: 268.642670\n",
      "Layer: 2, Epoch: 7 --- Error: 265.589325\n",
      "Layer: 2, Epoch: 8 --- Error: 262.207214\n",
      "Layer: 2, Epoch: 9 --- Error: 258.592194\n",
      "Layer: 2, Epoch: 10 --- Error: 255.045700\n",
      "Layer: 2, Epoch: 11 --- Error: 251.074020\n",
      "Layer: 2, Epoch: 12 --- Error: 246.803452\n",
      "Layer: 2, Epoch: 13 --- Error: 243.120743\n",
      "Layer: 2, Epoch: 14 --- Error: 239.727341\n",
      "Layer: 2, Epoch: 15 --- Error: 236.298080\n",
      "Layer: 2, Epoch: 16 --- Error: 232.794617\n",
      "Layer: 2, Epoch: 17 --- Error: 230.429520\n",
      "Layer: 2, Epoch: 18 --- Error: 227.560822\n",
      "Layer: 2, Epoch: 19 --- Error: 225.029678\n",
      "Layer: 2, Epoch: 20 --- Error: 222.735031\n",
      "Layer: 2, Epoch: 21 --- Error: 220.613235\n",
      "Layer: 2, Epoch: 22 --- Error: 218.174515\n",
      "Layer: 2, Epoch: 23 --- Error: 216.084320\n",
      "Layer: 2, Epoch: 24 --- Error: 213.863632\n",
      "Layer: 2, Epoch: 25 --- Error: 212.074677\n",
      "Layer: 2, Epoch: 26 --- Error: 210.141647\n",
      "Layer: 2, Epoch: 27 --- Error: 208.544998\n",
      "Layer: 2, Epoch: 28 --- Error: 206.699860\n",
      "Layer: 2, Epoch: 29 --- Error: 205.278702\n",
      "Layer: 2, Epoch: 30 --- Error: 203.946625\n",
      "Layer: 2, Epoch: 31 --- Error: 202.639557\n",
      "Layer: 2, Epoch: 32 --- Error: 200.815613\n",
      "Layer: 2, Epoch: 33 --- Error: 199.662079\n",
      "Layer: 2, Epoch: 34 --- Error: 198.622726\n",
      "Layer: 2, Epoch: 35 --- Error: 197.416199\n",
      "Layer: 2, Epoch: 36 --- Error: 195.682510\n",
      "Layer: 2, Epoch: 37 --- Error: 194.700714\n",
      "Layer: 2, Epoch: 38 --- Error: 193.517334\n",
      "Layer: 2, Epoch: 39 --- Error: 192.745514\n",
      "Layer: 2, Epoch: 40 --- Error: 191.792282\n",
      "Layer: 2, Epoch: 41 --- Error: 190.014908\n",
      "Layer: 2, Epoch: 42 --- Error: 188.845840\n",
      "Layer: 2, Epoch: 43 --- Error: 188.349869\n",
      "Layer: 2, Epoch: 44 --- Error: 187.561630\n",
      "Layer: 2, Epoch: 45 --- Error: 186.445404\n",
      "Layer: 2, Epoch: 46 --- Error: 185.847244\n",
      "Layer: 2, Epoch: 47 --- Error: 184.884750\n",
      "Layer: 2, Epoch: 48 --- Error: 183.757828\n",
      "Layer: 2, Epoch: 49 --- Error: 182.704620\n",
      "Layer: 2, Epoch: 50 --- Error: 181.909714\n",
      "Layer: 2, Epoch: 51 --- Error: 181.662003\n",
      "Layer: 2, Epoch: 52 --- Error: 180.754166\n",
      "Layer: 2, Epoch: 53 --- Error: 179.802933\n",
      "Layer: 2, Epoch: 54 --- Error: 179.288315\n",
      "Layer: 2, Epoch: 55 --- Error: 178.025803\n",
      "Layer: 2, Epoch: 56 --- Error: 177.711151\n",
      "Layer: 2, Epoch: 57 --- Error: 177.088425\n",
      "Layer: 2, Epoch: 58 --- Error: 176.357605\n",
      "Layer: 2, Epoch: 59 --- Error: 175.793228\n",
      "Layer: 2, Epoch: 60 --- Error: 174.830124\n",
      "Layer: 2, Epoch: 61 --- Error: 174.029861\n",
      "Layer: 2, Epoch: 62 --- Error: 173.702209\n",
      "Layer: 2, Epoch: 63 --- Error: 172.801468\n",
      "Layer: 2, Epoch: 64 --- Error: 172.563812\n",
      "Layer: 2, Epoch: 65 --- Error: 172.178680\n",
      "Layer: 2, Epoch: 66 --- Error: 171.487015\n",
      "Layer: 2, Epoch: 67 --- Error: 171.044464\n",
      "Layer: 2, Epoch: 68 --- Error: 170.693634\n",
      "Layer: 2, Epoch: 69 --- Error: 170.024567\n",
      "Layer: 2, Epoch: 70 --- Error: 169.560486\n",
      "Layer: 2, Epoch: 71 --- Error: 168.707230\n",
      "Layer: 2, Epoch: 72 --- Error: 168.150665\n",
      "Layer: 2, Epoch: 73 --- Error: 168.090393\n",
      "Layer: 2, Epoch: 74 --- Error: 167.570602\n",
      "Layer: 2, Epoch: 75 --- Error: 166.471863\n",
      "Layer: 2, Epoch: 76 --- Error: 166.367325\n",
      "Layer: 2, Epoch: 77 --- Error: 165.688477\n",
      "Layer: 2, Epoch: 78 --- Error: 165.420929\n",
      "Layer: 2, Epoch: 79 --- Error: 165.169373\n",
      "Layer: 2, Epoch: 80 --- Error: 163.823303\n",
      "Layer: 2, Epoch: 81 --- Error: 164.133331\n",
      "Layer: 2, Epoch: 82 --- Error: 163.934921\n",
      "Layer: 2, Epoch: 83 --- Error: 163.212479\n",
      "Layer: 2, Epoch: 84 --- Error: 163.063583\n",
      "Layer: 2, Epoch: 85 --- Error: 162.553406\n",
      "Layer: 2, Epoch: 86 --- Error: 161.780243\n",
      "Layer: 2, Epoch: 87 --- Error: 161.854050\n",
      "Layer: 2, Epoch: 88 --- Error: 161.264557\n",
      "Layer: 2, Epoch: 89 --- Error: 161.067871\n",
      "Layer: 2, Epoch: 90 --- Error: 160.593048\n",
      "Layer: 2, Epoch: 91 --- Error: 160.174820\n",
      "Layer: 2, Epoch: 92 --- Error: 160.153351\n",
      "Layer: 2, Epoch: 93 --- Error: 159.575333\n",
      "Layer: 2, Epoch: 94 --- Error: 158.972137\n",
      "Layer: 2, Epoch: 95 --- Error: 159.087906\n",
      "Layer: 2, Epoch: 96 --- Error: 158.864777\n",
      "Layer: 2, Epoch: 97 --- Error: 157.770050\n",
      "Layer: 2, Epoch: 98 --- Error: 157.660492\n",
      "Layer: 2, Epoch: 99 --- Error: 157.756912\n",
      "Layer: 2, Epoch: 100 --- Error: 157.655930\n",
      "Layer: 2, Epoch: 101 --- Error: 156.984970\n",
      "Layer: 2, Epoch: 102 --- Error: 156.724228\n",
      "Layer: 2, Epoch: 103 --- Error: 156.473068\n",
      "Layer: 2, Epoch: 104 --- Error: 156.412323\n",
      "Layer: 2, Epoch: 105 --- Error: 155.583359\n",
      "Layer: 2, Epoch: 106 --- Error: 155.486038\n",
      "Layer: 2, Epoch: 107 --- Error: 155.367432\n",
      "Layer: 2, Epoch: 108 --- Error: 155.149628\n",
      "Layer: 2, Epoch: 109 --- Error: 154.893341\n",
      "Layer: 2, Epoch: 110 --- Error: 155.191269\n",
      "Layer: 2, Epoch: 111 --- Error: 154.735382\n",
      "Layer: 2, Epoch: 112 --- Error: 154.218414\n",
      "Layer: 2, Epoch: 113 --- Error: 153.054398\n",
      "Layer: 2, Epoch: 114 --- Error: 153.684265\n",
      "Layer: 2, Epoch: 115 --- Error: 152.953705\n",
      "Layer: 2, Epoch: 116 --- Error: 152.865738\n",
      "Layer: 2, Epoch: 117 --- Error: 153.195526\n",
      "Layer: 2, Epoch: 118 --- Error: 152.767899\n",
      "Layer: 2, Epoch: 119 --- Error: 152.639359\n",
      "Layer: 2, Epoch: 120 --- Error: 152.030777\n",
      "Layer: 2, Epoch: 121 --- Error: 151.780991\n",
      "Layer: 2, Epoch: 122 --- Error: 151.789154\n",
      "Layer: 2, Epoch: 123 --- Error: 151.291702\n",
      "Layer: 2, Epoch: 124 --- Error: 151.117828\n",
      "Layer: 2, Epoch: 125 --- Error: 150.883835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 2, Epoch: 126 --- Error: 151.400803\n",
      "Layer: 2, Epoch: 127 --- Error: 150.637939\n",
      "Layer: 2, Epoch: 128 --- Error: 150.560791\n",
      "Layer: 2, Epoch: 129 --- Error: 150.167282\n",
      "Layer: 2, Epoch: 130 --- Error: 150.315430\n",
      "Layer: 2, Epoch: 131 --- Error: 149.748367\n",
      "Layer: 2, Epoch: 132 --- Error: 149.663895\n",
      "Layer: 2, Epoch: 133 --- Error: 149.392899\n",
      "Layer: 2, Epoch: 134 --- Error: 149.356522\n",
      "Layer: 2, Epoch: 135 --- Error: 148.980042\n",
      "Layer: 2, Epoch: 136 --- Error: 149.002655\n",
      "Layer: 2, Epoch: 137 --- Error: 148.959671\n",
      "Layer: 2, Epoch: 138 --- Error: 148.825775\n",
      "Layer: 2, Epoch: 139 --- Error: 148.237640\n",
      "Layer: 2, Epoch: 140 --- Error: 147.834976\n",
      "Layer: 2, Epoch: 141 --- Error: 148.326324\n",
      "Layer: 2, Epoch: 142 --- Error: 148.230789\n",
      "Layer: 2, Epoch: 143 --- Error: 147.992722\n",
      "Layer: 2, Epoch: 144 --- Error: 147.230408\n",
      "Layer: 2, Epoch: 145 --- Error: 147.080765\n",
      "Layer: 2, Epoch: 146 --- Error: 147.254120\n",
      "Layer: 2, Epoch: 147 --- Error: 147.194183\n",
      "Layer: 2, Epoch: 148 --- Error: 147.064911\n",
      "Layer: 2, Epoch: 149 --- Error: 146.655319\n",
      "Layer: 2, Epoch: 150 --- Error: 146.652695\n",
      "Layer: 2, Epoch: 151 --- Error: 146.416931\n",
      "Layer: 2, Epoch: 152 --- Error: 146.007584\n",
      "Layer: 2, Epoch: 153 --- Error: 146.301651\n",
      "Layer: 2, Epoch: 154 --- Error: 145.952530\n",
      "Layer: 2, Epoch: 155 --- Error: 145.996307\n",
      "Layer: 2, Epoch: 156 --- Error: 145.772949\n",
      "Layer: 2, Epoch: 157 --- Error: 145.722504\n",
      "Layer: 2, Epoch: 158 --- Error: 145.411316\n",
      "Layer: 2, Epoch: 159 --- Error: 145.643982\n",
      "Layer: 2, Epoch: 160 --- Error: 145.417725\n",
      "Layer: 2, Epoch: 161 --- Error: 145.106400\n",
      "Layer: 2, Epoch: 162 --- Error: 144.756104\n",
      "Layer: 2, Epoch: 163 --- Error: 144.584869\n",
      "Layer: 2, Epoch: 164 --- Error: 144.748520\n",
      "Layer: 2, Epoch: 165 --- Error: 144.358398\n",
      "Layer: 2, Epoch: 166 --- Error: 144.229752\n",
      "Layer: 2, Epoch: 167 --- Error: 144.166702\n",
      "Layer: 2, Epoch: 168 --- Error: 144.017090\n",
      "Layer: 2, Epoch: 169 --- Error: 143.751938\n",
      "Layer: 2, Epoch: 170 --- Error: 144.160309\n",
      "Layer: 2, Epoch: 171 --- Error: 144.113571\n",
      "Layer: 2, Epoch: 172 --- Error: 143.671921\n",
      "Layer: 2, Epoch: 173 --- Error: 143.063705\n",
      "Layer: 2, Epoch: 174 --- Error: 143.474121\n",
      "Layer: 2, Epoch: 175 --- Error: 143.386566\n",
      "Layer: 2, Epoch: 176 --- Error: 143.351151\n",
      "Layer: 2, Epoch: 177 --- Error: 143.193787\n",
      "Layer: 2, Epoch: 178 --- Error: 143.073929\n",
      "Layer: 2, Epoch: 179 --- Error: 143.014359\n",
      "Layer: 2, Epoch: 180 --- Error: 142.710495\n",
      "Layer: 2, Epoch: 181 --- Error: 142.114456\n",
      "Layer: 2, Epoch: 182 --- Error: 142.611893\n",
      "Layer: 2, Epoch: 183 --- Error: 142.483994\n",
      "Layer: 2, Epoch: 184 --- Error: 142.337173\n",
      "Layer: 2, Epoch: 185 --- Error: 142.300674\n",
      "Layer: 2, Epoch: 186 --- Error: 141.596954\n",
      "Layer: 2, Epoch: 187 --- Error: 141.961365\n",
      "Layer: 2, Epoch: 188 --- Error: 142.094666\n",
      "Layer: 2, Epoch: 189 --- Error: 141.753128\n",
      "Layer: 2, Epoch: 190 --- Error: 142.045898\n",
      "Layer: 2, Epoch: 191 --- Error: 141.517380\n",
      "Layer: 2, Epoch: 192 --- Error: 141.420670\n",
      "Layer: 2, Epoch: 193 --- Error: 141.486496\n",
      "Layer: 2, Epoch: 194 --- Error: 141.541672\n",
      "Layer: 2, Epoch: 195 --- Error: 141.549042\n",
      "Layer: 2, Epoch: 196 --- Error: 141.095505\n",
      "Layer: 2, Epoch: 197 --- Error: 140.956451\n",
      "Layer: 2, Epoch: 198 --- Error: 141.150253\n",
      "Layer: 2, Epoch: 199 --- Error: 141.043396\n",
      "Layer: 2, Epoch: 200 --- Error: 141.071732\n",
      "Layer: 2, Epoch: 201 --- Error: 141.062561\n",
      "Layer: 2, Epoch: 202 --- Error: 140.663559\n",
      "Layer: 2, Epoch: 203 --- Error: 140.792435\n",
      "Layer: 2, Epoch: 204 --- Error: 140.797256\n",
      "Layer: 2, Epoch: 205 --- Error: 140.373810\n",
      "Layer: 2, Epoch: 206 --- Error: 140.212250\n",
      "Layer: 2, Epoch: 207 --- Error: 140.481308\n",
      "Layer: 2, Epoch: 208 --- Error: 140.519974\n",
      "Layer: 2, Epoch: 209 --- Error: 139.905701\n",
      "Layer: 2, Epoch: 210 --- Error: 140.034515\n",
      "Layer: 2, Epoch: 211 --- Error: 140.229950\n",
      "Layer: 2, Epoch: 212 --- Error: 140.177887\n",
      "Layer: 2, Epoch: 213 --- Error: 140.318176\n",
      "Layer: 2, Epoch: 214 --- Error: 139.710297\n",
      "Layer: 2, Epoch: 215 --- Error: 139.339752\n",
      "Layer: 2, Epoch: 216 --- Error: 140.007919\n",
      "Layer: 2, Epoch: 217 --- Error: 139.827423\n",
      "Layer: 2, Epoch: 218 --- Error: 139.688873\n",
      "Layer: 2, Epoch: 219 --- Error: 139.442139\n",
      "Layer: 2, Epoch: 220 --- Error: 139.213654\n",
      "Layer: 2, Epoch: 221 --- Error: 139.164734\n",
      "Layer: 2, Epoch: 222 --- Error: 139.210022\n",
      "Layer: 2, Epoch: 223 --- Error: 139.235214\n",
      "Layer: 2, Epoch: 224 --- Error: 139.320358\n",
      "Layer: 2, Epoch: 225 --- Error: 138.911041\n",
      "Layer: 2, Epoch: 226 --- Error: 139.049454\n",
      "Layer: 2, Epoch: 227 --- Error: 138.953552\n",
      "Layer: 2, Epoch: 228 --- Error: 138.826324\n",
      "Layer: 2, Epoch: 229 --- Error: 138.778717\n",
      "Layer: 2, Epoch: 230 --- Error: 138.851822\n",
      "Layer: 2, Epoch: 231 --- Error: 138.578537\n",
      "Layer: 2, Epoch: 232 --- Error: 138.964066\n",
      "Layer: 2, Epoch: 233 --- Error: 138.601288\n",
      "Layer: 2, Epoch: 234 --- Error: 138.937057\n",
      "Layer: 2, Epoch: 235 --- Error: 138.127060\n",
      "Layer: 2, Epoch: 236 --- Error: 138.422028\n",
      "Layer: 2, Epoch: 237 --- Error: 138.084564\n",
      "Layer: 2, Epoch: 238 --- Error: 138.165466\n",
      "Layer: 2, Epoch: 239 --- Error: 138.264130\n",
      "Layer: 2, Epoch: 240 --- Error: 138.209305\n",
      "Layer: 2, Epoch: 241 --- Error: 137.929535\n",
      "Layer: 2, Epoch: 242 --- Error: 138.210434\n",
      "Layer: 2, Epoch: 243 --- Error: 138.493362\n",
      "Layer: 2, Epoch: 244 --- Error: 137.747406\n",
      "Layer: 2, Epoch: 245 --- Error: 137.909393\n",
      "Layer: 2, Epoch: 246 --- Error: 137.477051\n",
      "Layer: 2, Epoch: 247 --- Error: 137.735428\n",
      "Layer: 2, Epoch: 248 --- Error: 138.061951\n",
      "Layer: 2, Epoch: 249 --- Error: 137.802429\n",
      "Layer: 2, Epoch: 250 --- Error: 137.824951\n",
      "Layer: 2, Epoch: 251 --- Error: 137.488495\n",
      "Layer: 2, Epoch: 252 --- Error: 137.308640\n",
      "Layer: 2, Epoch: 253 --- Error: 137.467545\n",
      "Layer: 2, Epoch: 254 --- Error: 137.157700\n",
      "Layer: 2, Epoch: 255 --- Error: 137.425186\n",
      "Layer: 2, Epoch: 256 --- Error: 137.300430\n",
      "Layer: 2, Epoch: 257 --- Error: 137.325607\n",
      "Layer: 2, Epoch: 258 --- Error: 137.140335\n",
      "Layer: 2, Epoch: 259 --- Error: 137.192307\n",
      "Layer: 2, Epoch: 260 --- Error: 137.441635\n",
      "Layer: 2, Epoch: 261 --- Error: 137.163818\n",
      "Layer: 2, Epoch: 262 --- Error: 137.272720\n",
      "Layer: 2, Epoch: 263 --- Error: 136.851349\n",
      "Layer: 2, Epoch: 264 --- Error: 136.973343\n",
      "Layer: 2, Epoch: 265 --- Error: 136.950623\n",
      "Layer: 2, Epoch: 266 --- Error: 136.931137\n",
      "Layer: 2, Epoch: 267 --- Error: 136.882019\n",
      "Layer: 2, Epoch: 268 --- Error: 136.842606\n",
      "Layer: 2, Epoch: 269 --- Error: 137.121811\n",
      "Layer: 2, Epoch: 270 --- Error: 136.799011\n",
      "Layer: 2, Epoch: 271 --- Error: 136.345428\n",
      "Layer: 2, Epoch: 272 --- Error: 136.689102\n",
      "Layer: 2, Epoch: 273 --- Error: 136.669785\n",
      "Layer: 2, Epoch: 274 --- Error: 136.852585\n",
      "Layer: 2, Epoch: 275 --- Error: 136.386108\n",
      "Layer: 2, Epoch: 276 --- Error: 136.271301\n",
      "Layer: 2, Epoch: 277 --- Error: 136.309097\n",
      "Layer: 2, Epoch: 278 --- Error: 136.227829\n",
      "Layer: 2, Epoch: 279 --- Error: 136.201218\n",
      "Layer: 2, Epoch: 280 --- Error: 136.298523\n",
      "Layer: 2, Epoch: 281 --- Error: 136.343369\n",
      "Layer: 2, Epoch: 282 --- Error: 135.785385\n",
      "Layer: 2, Epoch: 283 --- Error: 136.435745\n",
      "Layer: 2, Epoch: 284 --- Error: 136.184021\n",
      "Layer: 2, Epoch: 285 --- Error: 136.161850\n",
      "Layer: 2, Epoch: 286 --- Error: 135.942474\n",
      "Layer: 2, Epoch: 287 --- Error: 135.789261\n",
      "Layer: 2, Epoch: 288 --- Error: 135.603912\n",
      "Layer: 2, Epoch: 289 --- Error: 135.790466\n",
      "Layer: 2, Epoch: 290 --- Error: 136.211716\n",
      "Layer: 2, Epoch: 291 --- Error: 135.803940\n",
      "Layer: 2, Epoch: 292 --- Error: 135.763885\n",
      "Layer: 2, Epoch: 293 --- Error: 135.652573\n",
      "Layer: 2, Epoch: 294 --- Error: 135.845779\n",
      "Layer: 2, Epoch: 295 --- Error: 135.568161\n",
      "Layer: 2, Epoch: 296 --- Error: 135.605667\n",
      "Layer: 2, Epoch: 297 --- Error: 135.532913\n",
      "Layer: 2, Epoch: 298 --- Error: 135.657471\n",
      "Layer: 2, Epoch: 299 --- Error: 135.694305\n",
      "Layer: 2, Epoch: 300 --- Error: 135.509552\n",
      "Layer: 2, Epoch: 301 --- Error: 135.733994\n",
      "Layer: 2, Epoch: 302 --- Error: 135.455597\n",
      "Layer: 2, Epoch: 303 --- Error: 135.291580\n",
      "Layer: 2, Epoch: 304 --- Error: 135.211685\n",
      "Layer: 2, Epoch: 305 --- Error: 135.361252\n",
      "Layer: 2, Epoch: 306 --- Error: 135.557190\n",
      "Layer: 2, Epoch: 307 --- Error: 135.411575\n",
      "Layer: 2, Epoch: 308 --- Error: 135.454956\n",
      "Layer: 2, Epoch: 309 --- Error: 135.416290\n",
      "Layer: 2, Epoch: 310 --- Error: 135.239487\n",
      "Layer: 2, Epoch: 311 --- Error: 135.159775\n",
      "Layer: 2, Epoch: 312 --- Error: 135.240280\n",
      "Layer: 2, Epoch: 313 --- Error: 135.392670\n",
      "Layer: 2, Epoch: 314 --- Error: 135.224258\n",
      "Layer: 2, Epoch: 315 --- Error: 135.132904\n",
      "Layer: 2, Epoch: 316 --- Error: 135.038910\n",
      "Layer: 2, Epoch: 317 --- Error: 135.024796\n",
      "Layer: 2, Epoch: 318 --- Error: 135.200500\n",
      "Layer: 2, Epoch: 319 --- Error: 135.027573\n",
      "Layer: 2, Epoch: 320 --- Error: 135.090073\n",
      "Layer: 2, Epoch: 321 --- Error: 134.974472\n",
      "Layer: 2, Epoch: 322 --- Error: 135.349640\n",
      "Layer: 2, Epoch: 323 --- Error: 134.715485\n",
      "Layer: 2, Epoch: 324 --- Error: 134.878784\n",
      "Layer: 2, Epoch: 325 --- Error: 134.797348\n",
      "Layer: 2, Epoch: 326 --- Error: 134.831482\n",
      "Layer: 2, Epoch: 327 --- Error: 134.438004\n",
      "Layer: 2, Epoch: 328 --- Error: 134.784286\n",
      "Layer: 2, Epoch: 329 --- Error: 134.729187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 2, Epoch: 330 --- Error: 134.819901\n",
      "Layer: 2, Epoch: 331 --- Error: 134.673035\n",
      "Layer: 2, Epoch: 332 --- Error: 134.743912\n",
      "Layer: 2, Epoch: 333 --- Error: 134.832779\n",
      "Layer: 2, Epoch: 334 --- Error: 134.313721\n",
      "Layer: 2, Epoch: 335 --- Error: 134.235046\n",
      "Layer: 2, Epoch: 336 --- Error: 134.781082\n",
      "Layer: 2, Epoch: 337 --- Error: 134.381546\n",
      "Layer: 2, Epoch: 338 --- Error: 134.614914\n",
      "Layer: 2, Epoch: 339 --- Error: 134.378082\n",
      "Layer: 2, Epoch: 340 --- Error: 134.412430\n",
      "Layer: 2, Epoch: 341 --- Error: 134.705597\n",
      "Layer: 2, Epoch: 342 --- Error: 134.649582\n",
      "Layer: 2, Epoch: 343 --- Error: 134.691925\n",
      "Layer: 2, Epoch: 344 --- Error: 134.388336\n",
      "Layer: 2, Epoch: 345 --- Error: 134.323135\n",
      "Layer: 2, Epoch: 346 --- Error: 134.392715\n",
      "Layer: 2, Epoch: 347 --- Error: 134.098602\n",
      "Layer: 2, Epoch: 348 --- Error: 134.264801\n",
      "Layer: 2, Epoch: 349 --- Error: 134.427231\n",
      "Layer: 2, Epoch: 350 --- Error: 134.299255\n",
      "Layer: 2, Epoch: 351 --- Error: 134.052948\n",
      "Layer: 2, Epoch: 352 --- Error: 134.073883\n",
      "Layer: 2, Epoch: 353 --- Error: 134.392151\n",
      "Layer: 2, Epoch: 354 --- Error: 134.293137\n",
      "Layer: 2, Epoch: 355 --- Error: 133.888382\n",
      "Layer: 2, Epoch: 356 --- Error: 134.260101\n",
      "Layer: 2, Epoch: 357 --- Error: 134.233810\n",
      "Layer: 2, Epoch: 358 --- Error: 133.781342\n",
      "Layer: 2, Epoch: 359 --- Error: 133.917664\n",
      "Layer: 2, Epoch: 360 --- Error: 133.953934\n",
      "Layer: 2, Epoch: 361 --- Error: 133.847137\n",
      "Layer: 2, Epoch: 362 --- Error: 134.103729\n",
      "Layer: 2, Epoch: 363 --- Error: 133.761154\n",
      "Layer: 2, Epoch: 364 --- Error: 133.974182\n",
      "Layer: 2, Epoch: 365 --- Error: 134.183151\n",
      "Layer: 2, Epoch: 366 --- Error: 133.849731\n",
      "Layer: 2, Epoch: 367 --- Error: 133.743713\n",
      "Layer: 2, Epoch: 368 --- Error: 133.926437\n",
      "Layer: 2, Epoch: 369 --- Error: 133.645309\n",
      "Layer: 2, Epoch: 370 --- Error: 133.530441\n",
      "Layer: 2, Epoch: 371 --- Error: 133.569031\n",
      "Layer: 2, Epoch: 372 --- Error: 133.707718\n",
      "Layer: 2, Epoch: 373 --- Error: 134.081650\n",
      "Layer: 2, Epoch: 374 --- Error: 133.371475\n",
      "Layer: 2, Epoch: 375 --- Error: 133.870667\n",
      "Layer: 2, Epoch: 376 --- Error: 133.262955\n",
      "Layer: 2, Epoch: 377 --- Error: 133.786484\n",
      "Layer: 2, Epoch: 378 --- Error: 134.044464\n",
      "Layer: 2, Epoch: 379 --- Error: 133.421371\n",
      "Layer: 2, Epoch: 380 --- Error: 133.542282\n",
      "Layer: 2, Epoch: 381 --- Error: 133.588058\n",
      "Layer: 2, Epoch: 382 --- Error: 133.676971\n",
      "Layer: 2, Epoch: 383 --- Error: 133.892609\n",
      "Layer: 2, Epoch: 384 --- Error: 133.630325\n",
      "Layer: 2, Epoch: 385 --- Error: 134.169952\n",
      "Layer: 2, Epoch: 386 --- Error: 133.247498\n",
      "Layer: 2, Epoch: 387 --- Error: 133.492950\n",
      "Layer: 2, Epoch: 388 --- Error: 133.554657\n",
      "Layer: 2, Epoch: 389 --- Error: 133.531906\n",
      "Layer: 2, Epoch: 390 --- Error: 133.534546\n",
      "Layer: 2, Epoch: 391 --- Error: 133.475113\n",
      "Layer: 2, Epoch: 392 --- Error: 133.495316\n",
      "Layer: 2, Epoch: 393 --- Error: 133.227097\n",
      "Layer: 2, Epoch: 394 --- Error: 133.179749\n",
      "Layer: 2, Epoch: 395 --- Error: 133.102081\n",
      "Layer: 2, Epoch: 396 --- Error: 133.255936\n",
      "Layer: 2, Epoch: 397 --- Error: 133.513245\n",
      "Layer: 2, Epoch: 398 --- Error: 133.150879\n",
      "Layer: 2, Epoch: 399 --- Error: 133.297104\n",
      "Layer: 2, Epoch: 400 --- Error: 133.243103\n",
      "Layer: 2, Epoch: 401 --- Error: 133.150375\n",
      "Layer: 2, Epoch: 402 --- Error: 133.306839\n",
      "Layer: 2, Epoch: 403 --- Error: 133.173050\n",
      "Layer: 2, Epoch: 404 --- Error: 133.275024\n",
      "Layer: 2, Epoch: 405 --- Error: 133.209045\n",
      "Layer: 2, Epoch: 406 --- Error: 133.513748\n",
      "Layer: 2, Epoch: 407 --- Error: 133.295151\n",
      "Layer: 2, Epoch: 408 --- Error: 133.151886\n",
      "Layer: 2, Epoch: 409 --- Error: 133.127411\n",
      "Layer: 2, Epoch: 410 --- Error: 133.058990\n",
      "Layer: 2, Epoch: 411 --- Error: 133.220291\n",
      "Layer: 2, Epoch: 412 --- Error: 133.058258\n",
      "Layer: 2, Epoch: 413 --- Error: 133.182114\n",
      "Layer: 2, Epoch: 414 --- Error: 133.336578\n",
      "Layer: 2, Epoch: 415 --- Error: 132.938751\n",
      "Layer: 2, Epoch: 416 --- Error: 132.744492\n",
      "Layer: 2, Epoch: 417 --- Error: 132.665085\n",
      "Layer: 2, Epoch: 418 --- Error: 132.817001\n",
      "Layer: 2, Epoch: 419 --- Error: 132.998962\n",
      "Layer: 2, Epoch: 420 --- Error: 133.343872\n",
      "Layer: 2, Epoch: 421 --- Error: 132.793167\n",
      "Layer: 2, Epoch: 422 --- Error: 133.106659\n",
      "Layer: 2, Epoch: 423 --- Error: 132.637955\n",
      "Layer: 2, Epoch: 424 --- Error: 132.858414\n",
      "Layer: 2, Epoch: 425 --- Error: 132.677094\n",
      "Layer: 2, Epoch: 426 --- Error: 132.999664\n",
      "Layer: 2, Epoch: 427 --- Error: 132.734329\n",
      "Layer: 2, Epoch: 428 --- Error: 133.043533\n",
      "Layer: 2, Epoch: 429 --- Error: 132.770081\n",
      "Layer: 2, Epoch: 430 --- Error: 132.697098\n",
      "Layer: 2, Epoch: 431 --- Error: 132.880508\n",
      "Layer: 2, Epoch: 432 --- Error: 132.651199\n",
      "Layer: 2, Epoch: 433 --- Error: 132.947296\n",
      "Layer: 2, Epoch: 434 --- Error: 132.930283\n",
      "Layer: 2, Epoch: 435 --- Error: 132.556824\n",
      "Layer: 2, Epoch: 436 --- Error: 132.621109\n",
      "Layer: 2, Epoch: 437 --- Error: 132.553207\n",
      "Layer: 2, Epoch: 438 --- Error: 132.671173\n",
      "Layer: 2, Epoch: 439 --- Error: 132.211746\n",
      "Layer: 2, Epoch: 440 --- Error: 132.514938\n",
      "Layer: 2, Epoch: 441 --- Error: 132.472397\n",
      "Layer: 2, Epoch: 442 --- Error: 132.624817\n",
      "Layer: 2, Epoch: 443 --- Error: 132.358414\n",
      "Layer: 2, Epoch: 444 --- Error: 132.626312\n",
      "Layer: 2, Epoch: 445 --- Error: 132.355087\n",
      "Layer: 2, Epoch: 446 --- Error: 132.418686\n",
      "Layer: 2, Epoch: 447 --- Error: 132.445175\n",
      "Layer: 2, Epoch: 448 --- Error: 132.411728\n",
      "Layer: 2, Epoch: 449 --- Error: 132.195862\n",
      "Layer: 2, Epoch: 450 --- Error: 132.710556\n",
      "Layer: 2, Epoch: 451 --- Error: 132.655838\n",
      "Layer: 2, Epoch: 452 --- Error: 132.081940\n",
      "Layer: 2, Epoch: 453 --- Error: 132.489670\n",
      "Layer: 2, Epoch: 454 --- Error: 132.632339\n",
      "Layer: 2, Epoch: 455 --- Error: 132.370026\n",
      "Layer: 2, Epoch: 456 --- Error: 132.774155\n",
      "Layer: 2, Epoch: 457 --- Error: 132.751892\n",
      "Layer: 2, Epoch: 458 --- Error: 132.563202\n",
      "Layer: 2, Epoch: 459 --- Error: 132.340805\n",
      "Layer: 2, Epoch: 460 --- Error: 132.405716\n",
      "Layer: 2, Epoch: 461 --- Error: 132.461273\n",
      "Layer: 2, Epoch: 462 --- Error: 132.165253\n",
      "Layer: 2, Epoch: 463 --- Error: 132.444778\n",
      "Layer: 2, Epoch: 464 --- Error: 132.381531\n",
      "Layer: 2, Epoch: 465 --- Error: 132.428162\n",
      "Layer: 2, Epoch: 466 --- Error: 132.292969\n",
      "Layer: 2, Epoch: 467 --- Error: 132.144058\n",
      "Layer: 2, Epoch: 468 --- Error: 132.635681\n",
      "Layer: 2, Epoch: 469 --- Error: 132.199707\n",
      "Layer: 2, Epoch: 470 --- Error: 132.131851\n",
      "Layer: 2, Epoch: 471 --- Error: 132.317047\n",
      "Layer: 2, Epoch: 472 --- Error: 132.181564\n",
      "Layer: 2, Epoch: 473 --- Error: 132.290878\n",
      "Layer: 2, Epoch: 474 --- Error: 132.245514\n",
      "Layer: 2, Epoch: 475 --- Error: 132.383789\n",
      "Layer: 2, Epoch: 476 --- Error: 132.087357\n",
      "Layer: 2, Epoch: 477 --- Error: 132.123154\n",
      "Layer: 2, Epoch: 478 --- Error: 132.442429\n",
      "Layer: 2, Epoch: 479 --- Error: 132.236511\n",
      "Layer: 2, Epoch: 480 --- Error: 132.318878\n",
      "Layer: 2, Epoch: 481 --- Error: 131.993729\n",
      "Layer: 2, Epoch: 482 --- Error: 132.088913\n",
      "Layer: 2, Epoch: 483 --- Error: 132.292725\n",
      "Layer: 2, Epoch: 484 --- Error: 132.377777\n",
      "Layer: 2, Epoch: 485 --- Error: 132.093689\n",
      "Layer: 2, Epoch: 486 --- Error: 132.272324\n",
      "Layer: 2, Epoch: 487 --- Error: 131.887543\n",
      "Layer: 2, Epoch: 488 --- Error: 132.029160\n",
      "Layer: 2, Epoch: 489 --- Error: 132.315125\n",
      "Layer: 2, Epoch: 490 --- Error: 132.067780\n",
      "Layer: 2, Epoch: 491 --- Error: 132.065002\n",
      "Layer: 2, Epoch: 492 --- Error: 132.418640\n",
      "Layer: 2, Epoch: 493 --- Error: 132.056427\n",
      "Layer: 2, Epoch: 494 --- Error: 132.013824\n",
      "Layer: 2, Epoch: 495 --- Error: 131.999252\n",
      "Layer: 2, Epoch: 496 --- Error: 131.907394\n",
      "Layer: 2, Epoch: 497 --- Error: 132.445938\n",
      "Layer: 2, Epoch: 498 --- Error: 132.148636\n",
      "Layer: 2, Epoch: 499 --- Error: 132.274460\n",
      "Layer: 2, Epoch: 500 --- Error: 131.854202\n",
      "Layer: 3, Epoch: 1 --- Error: 139.041061\n",
      "Layer: 3, Epoch: 2 --- Error: 129.124115\n",
      "Layer: 3, Epoch: 3 --- Error: 126.597946\n",
      "Layer: 3, Epoch: 4 --- Error: 125.223480\n",
      "Layer: 3, Epoch: 5 --- Error: 124.110748\n",
      "Layer: 3, Epoch: 6 --- Error: 123.199188\n",
      "Layer: 3, Epoch: 7 --- Error: 122.363762\n",
      "Layer: 3, Epoch: 8 --- Error: 121.588120\n",
      "Layer: 3, Epoch: 9 --- Error: 121.057457\n",
      "Layer: 3, Epoch: 10 --- Error: 120.016411\n",
      "Layer: 3, Epoch: 11 --- Error: 119.210007\n",
      "Layer: 3, Epoch: 12 --- Error: 118.188042\n",
      "Layer: 3, Epoch: 13 --- Error: 117.225861\n",
      "Layer: 3, Epoch: 14 --- Error: 116.202797\n",
      "Layer: 3, Epoch: 15 --- Error: 114.982964\n",
      "Layer: 3, Epoch: 16 --- Error: 113.854279\n",
      "Layer: 3, Epoch: 17 --- Error: 112.867279\n",
      "Layer: 3, Epoch: 18 --- Error: 111.439323\n",
      "Layer: 3, Epoch: 19 --- Error: 110.168312\n",
      "Layer: 3, Epoch: 20 --- Error: 108.785873\n",
      "Layer: 3, Epoch: 21 --- Error: 107.574463\n",
      "Layer: 3, Epoch: 22 --- Error: 106.130684\n",
      "Layer: 3, Epoch: 23 --- Error: 105.200333\n",
      "Layer: 3, Epoch: 24 --- Error: 104.057442\n",
      "Layer: 3, Epoch: 25 --- Error: 102.697342\n",
      "Layer: 3, Epoch: 26 --- Error: 101.623703\n",
      "Layer: 3, Epoch: 27 --- Error: 100.473129\n",
      "Layer: 3, Epoch: 28 --- Error: 99.231270\n",
      "Layer: 3, Epoch: 29 --- Error: 98.387733\n",
      "Layer: 3, Epoch: 30 --- Error: 97.293282\n",
      "Layer: 3, Epoch: 31 --- Error: 96.514511\n",
      "Layer: 3, Epoch: 32 --- Error: 95.153526\n",
      "Layer: 3, Epoch: 33 --- Error: 94.405975\n",
      "Layer: 3, Epoch: 34 --- Error: 93.588547\n",
      "Layer: 3, Epoch: 35 --- Error: 92.524612\n",
      "Layer: 3, Epoch: 36 --- Error: 91.668526\n",
      "Layer: 3, Epoch: 37 --- Error: 91.104370\n",
      "Layer: 3, Epoch: 38 --- Error: 90.345932\n",
      "Layer: 3, Epoch: 39 --- Error: 89.549522\n",
      "Layer: 3, Epoch: 40 --- Error: 88.724129\n",
      "Layer: 3, Epoch: 41 --- Error: 87.829308\n",
      "Layer: 3, Epoch: 42 --- Error: 87.409203\n",
      "Layer: 3, Epoch: 43 --- Error: 86.556709\n",
      "Layer: 3, Epoch: 44 --- Error: 86.308708\n",
      "Layer: 3, Epoch: 45 --- Error: 85.192307\n",
      "Layer: 3, Epoch: 46 --- Error: 84.784599\n",
      "Layer: 3, Epoch: 47 --- Error: 83.930374\n",
      "Layer: 3, Epoch: 48 --- Error: 83.286156\n",
      "Layer: 3, Epoch: 49 --- Error: 82.463051\n",
      "Layer: 3, Epoch: 50 --- Error: 82.345749\n",
      "Layer: 3, Epoch: 51 --- Error: 81.697166\n",
      "Layer: 3, Epoch: 52 --- Error: 80.835678\n",
      "Layer: 3, Epoch: 53 --- Error: 80.296120\n",
      "Layer: 3, Epoch: 54 --- Error: 79.864914\n",
      "Layer: 3, Epoch: 55 --- Error: 79.393410\n",
      "Layer: 3, Epoch: 56 --- Error: 78.818954\n",
      "Layer: 3, Epoch: 57 --- Error: 78.037582\n",
      "Layer: 3, Epoch: 58 --- Error: 77.903908\n",
      "Layer: 3, Epoch: 59 --- Error: 77.347054\n",
      "Layer: 3, Epoch: 60 --- Error: 76.684975\n",
      "Layer: 3, Epoch: 61 --- Error: 76.614845\n",
      "Layer: 3, Epoch: 62 --- Error: 76.256744\n",
      "Layer: 3, Epoch: 63 --- Error: 75.828384\n",
      "Layer: 3, Epoch: 64 --- Error: 75.127518\n",
      "Layer: 3, Epoch: 65 --- Error: 74.392136\n",
      "Layer: 3, Epoch: 66 --- Error: 74.066391\n",
      "Layer: 3, Epoch: 67 --- Error: 74.120804\n",
      "Layer: 3, Epoch: 68 --- Error: 73.288483\n",
      "Layer: 3, Epoch: 69 --- Error: 72.764572\n",
      "Layer: 3, Epoch: 70 --- Error: 72.474617\n",
      "Layer: 3, Epoch: 71 --- Error: 72.093369\n",
      "Layer: 3, Epoch: 72 --- Error: 71.578667\n",
      "Layer: 3, Epoch: 73 --- Error: 71.419853\n",
      "Layer: 3, Epoch: 74 --- Error: 71.017014\n",
      "Layer: 3, Epoch: 75 --- Error: 70.396996\n",
      "Layer: 3, Epoch: 76 --- Error: 70.291718\n",
      "Layer: 3, Epoch: 77 --- Error: 69.956055\n",
      "Layer: 3, Epoch: 78 --- Error: 69.627045\n",
      "Layer: 3, Epoch: 79 --- Error: 69.234154\n",
      "Layer: 3, Epoch: 80 --- Error: 68.800751\n",
      "Layer: 3, Epoch: 81 --- Error: 68.751495\n",
      "Layer: 3, Epoch: 82 --- Error: 68.305199\n",
      "Layer: 3, Epoch: 83 --- Error: 67.761765\n",
      "Layer: 3, Epoch: 84 --- Error: 67.618774\n",
      "Layer: 3, Epoch: 85 --- Error: 66.916245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 3, Epoch: 86 --- Error: 66.782661\n",
      "Layer: 3, Epoch: 87 --- Error: 66.472275\n",
      "Layer: 3, Epoch: 88 --- Error: 66.457275\n",
      "Layer: 3, Epoch: 89 --- Error: 65.768074\n",
      "Layer: 3, Epoch: 90 --- Error: 65.319290\n",
      "Layer: 3, Epoch: 91 --- Error: 65.346123\n",
      "Layer: 3, Epoch: 92 --- Error: 64.985741\n",
      "Layer: 3, Epoch: 93 --- Error: 64.949898\n",
      "Layer: 3, Epoch: 94 --- Error: 64.443542\n",
      "Layer: 3, Epoch: 95 --- Error: 64.222633\n",
      "Layer: 3, Epoch: 96 --- Error: 64.095528\n",
      "Layer: 3, Epoch: 97 --- Error: 63.681957\n",
      "Layer: 3, Epoch: 98 --- Error: 63.540241\n",
      "Layer: 3, Epoch: 99 --- Error: 63.022068\n",
      "Layer: 3, Epoch: 100 --- Error: 62.432331\n",
      "Layer: 3, Epoch: 101 --- Error: 62.446526\n",
      "Layer: 3, Epoch: 102 --- Error: 62.016750\n",
      "Layer: 3, Epoch: 103 --- Error: 61.989304\n",
      "Layer: 3, Epoch: 104 --- Error: 61.262386\n",
      "Layer: 3, Epoch: 105 --- Error: 61.505287\n",
      "Layer: 3, Epoch: 106 --- Error: 61.245667\n",
      "Layer: 3, Epoch: 107 --- Error: 60.883198\n",
      "Layer: 3, Epoch: 108 --- Error: 60.723198\n",
      "Layer: 3, Epoch: 109 --- Error: 60.283646\n",
      "Layer: 3, Epoch: 110 --- Error: 60.245426\n",
      "Layer: 3, Epoch: 111 --- Error: 60.165230\n",
      "Layer: 3, Epoch: 112 --- Error: 59.420162\n",
      "Layer: 3, Epoch: 113 --- Error: 59.590591\n",
      "Layer: 3, Epoch: 114 --- Error: 59.234707\n",
      "Layer: 3, Epoch: 115 --- Error: 58.847633\n",
      "Layer: 3, Epoch: 116 --- Error: 58.827927\n",
      "Layer: 3, Epoch: 117 --- Error: 58.445946\n",
      "Layer: 3, Epoch: 118 --- Error: 57.901833\n",
      "Layer: 3, Epoch: 119 --- Error: 58.300098\n",
      "Layer: 3, Epoch: 120 --- Error: 57.679619\n",
      "Layer: 3, Epoch: 121 --- Error: 57.842430\n",
      "Layer: 3, Epoch: 122 --- Error: 57.350948\n",
      "Layer: 3, Epoch: 123 --- Error: 57.202217\n",
      "Layer: 3, Epoch: 124 --- Error: 57.189896\n",
      "Layer: 3, Epoch: 125 --- Error: 56.667648\n",
      "Layer: 3, Epoch: 126 --- Error: 57.121010\n",
      "Layer: 3, Epoch: 127 --- Error: 56.700565\n",
      "Layer: 3, Epoch: 128 --- Error: 56.075600\n",
      "Layer: 3, Epoch: 129 --- Error: 56.086990\n",
      "Layer: 3, Epoch: 130 --- Error: 56.045979\n",
      "Layer: 3, Epoch: 131 --- Error: 55.575443\n",
      "Layer: 3, Epoch: 132 --- Error: 55.867241\n",
      "Layer: 3, Epoch: 133 --- Error: 55.993675\n",
      "Layer: 3, Epoch: 134 --- Error: 54.991226\n",
      "Layer: 3, Epoch: 135 --- Error: 55.129570\n",
      "Layer: 3, Epoch: 136 --- Error: 54.956848\n",
      "Layer: 3, Epoch: 137 --- Error: 54.887344\n",
      "Layer: 3, Epoch: 138 --- Error: 54.519588\n",
      "Layer: 3, Epoch: 139 --- Error: 54.542458\n",
      "Layer: 3, Epoch: 140 --- Error: 54.205181\n",
      "Layer: 3, Epoch: 141 --- Error: 54.308765\n",
      "Layer: 3, Epoch: 142 --- Error: 53.652367\n",
      "Layer: 3, Epoch: 143 --- Error: 54.150959\n",
      "Layer: 3, Epoch: 144 --- Error: 53.598789\n",
      "Layer: 3, Epoch: 145 --- Error: 53.332874\n",
      "Layer: 3, Epoch: 146 --- Error: 53.106197\n",
      "Layer: 3, Epoch: 147 --- Error: 52.993362\n",
      "Layer: 3, Epoch: 148 --- Error: 52.828590\n",
      "Layer: 3, Epoch: 149 --- Error: 52.822430\n",
      "Layer: 3, Epoch: 150 --- Error: 52.543884\n",
      "Layer: 3, Epoch: 151 --- Error: 52.462166\n",
      "Layer: 3, Epoch: 152 --- Error: 52.085178\n",
      "Layer: 3, Epoch: 153 --- Error: 52.388996\n",
      "Layer: 3, Epoch: 154 --- Error: 52.028759\n",
      "Layer: 3, Epoch: 155 --- Error: 51.310959\n",
      "Layer: 3, Epoch: 156 --- Error: 51.718513\n",
      "Layer: 3, Epoch: 157 --- Error: 51.596699\n",
      "Layer: 3, Epoch: 158 --- Error: 51.107414\n",
      "Layer: 3, Epoch: 159 --- Error: 51.375523\n",
      "Layer: 3, Epoch: 160 --- Error: 51.230629\n",
      "Layer: 3, Epoch: 161 --- Error: 50.966103\n",
      "Layer: 3, Epoch: 162 --- Error: 50.817844\n",
      "Layer: 3, Epoch: 163 --- Error: 50.460682\n",
      "Layer: 3, Epoch: 164 --- Error: 50.560665\n",
      "Layer: 3, Epoch: 165 --- Error: 50.275993\n",
      "Layer: 3, Epoch: 166 --- Error: 50.413475\n",
      "Layer: 3, Epoch: 167 --- Error: 49.977234\n",
      "Layer: 3, Epoch: 168 --- Error: 49.909084\n",
      "Layer: 3, Epoch: 169 --- Error: 49.809998\n",
      "Layer: 3, Epoch: 170 --- Error: 49.840378\n",
      "Layer: 3, Epoch: 171 --- Error: 49.425320\n",
      "Layer: 3, Epoch: 172 --- Error: 49.718742\n",
      "Layer: 3, Epoch: 173 --- Error: 49.246967\n",
      "Layer: 3, Epoch: 174 --- Error: 49.074638\n",
      "Layer: 3, Epoch: 175 --- Error: 49.213535\n",
      "Layer: 3, Epoch: 176 --- Error: 49.145927\n",
      "Layer: 3, Epoch: 177 --- Error: 48.980286\n",
      "Layer: 3, Epoch: 178 --- Error: 48.936096\n",
      "Layer: 3, Epoch: 179 --- Error: 48.568829\n",
      "Layer: 3, Epoch: 180 --- Error: 48.318134\n",
      "Layer: 3, Epoch: 181 --- Error: 48.224144\n",
      "Layer: 3, Epoch: 182 --- Error: 47.774590\n",
      "Layer: 3, Epoch: 183 --- Error: 48.036156\n",
      "Layer: 3, Epoch: 184 --- Error: 47.609871\n",
      "Layer: 3, Epoch: 185 --- Error: 48.049702\n",
      "Layer: 3, Epoch: 186 --- Error: 47.410786\n",
      "Layer: 3, Epoch: 187 --- Error: 47.497272\n",
      "Layer: 3, Epoch: 188 --- Error: 47.688484\n",
      "Layer: 3, Epoch: 189 --- Error: 47.497150\n",
      "Layer: 3, Epoch: 190 --- Error: 46.730129\n",
      "Layer: 3, Epoch: 191 --- Error: 47.009754\n",
      "Layer: 3, Epoch: 192 --- Error: 46.839294\n",
      "Layer: 3, Epoch: 193 --- Error: 46.492970\n",
      "Layer: 3, Epoch: 194 --- Error: 46.837765\n",
      "Layer: 3, Epoch: 195 --- Error: 46.641472\n",
      "Layer: 3, Epoch: 196 --- Error: 46.521534\n",
      "Layer: 3, Epoch: 197 --- Error: 46.214104\n",
      "Layer: 3, Epoch: 198 --- Error: 46.806297\n",
      "Layer: 3, Epoch: 199 --- Error: 46.018440\n",
      "Layer: 3, Epoch: 200 --- Error: 45.767529\n",
      "Layer: 3, Epoch: 201 --- Error: 45.673840\n",
      "Layer: 3, Epoch: 202 --- Error: 45.950630\n",
      "Layer: 3, Epoch: 203 --- Error: 46.075317\n",
      "Layer: 3, Epoch: 204 --- Error: 45.831581\n",
      "Layer: 3, Epoch: 205 --- Error: 46.110752\n",
      "Layer: 3, Epoch: 206 --- Error: 45.335197\n",
      "Layer: 3, Epoch: 207 --- Error: 45.412434\n",
      "Layer: 3, Epoch: 208 --- Error: 44.986046\n",
      "Layer: 3, Epoch: 209 --- Error: 44.729206\n",
      "Layer: 3, Epoch: 210 --- Error: 44.859501\n",
      "Layer: 3, Epoch: 211 --- Error: 44.819996\n",
      "Layer: 3, Epoch: 212 --- Error: 44.910767\n",
      "Layer: 3, Epoch: 213 --- Error: 44.815857\n",
      "Layer: 3, Epoch: 214 --- Error: 44.722855\n",
      "Layer: 3, Epoch: 215 --- Error: 44.649620\n",
      "Layer: 3, Epoch: 216 --- Error: 44.302078\n",
      "Layer: 3, Epoch: 217 --- Error: 44.479004\n",
      "Layer: 3, Epoch: 218 --- Error: 44.364403\n",
      "Layer: 3, Epoch: 219 --- Error: 45.060970\n",
      "Layer: 3, Epoch: 220 --- Error: 43.838085\n",
      "Layer: 3, Epoch: 221 --- Error: 44.024269\n",
      "Layer: 3, Epoch: 222 --- Error: 44.005177\n",
      "Layer: 3, Epoch: 223 --- Error: 43.856030\n",
      "Layer: 3, Epoch: 224 --- Error: 43.794876\n",
      "Layer: 3, Epoch: 225 --- Error: 43.993595\n",
      "Layer: 3, Epoch: 226 --- Error: 43.987118\n",
      "Layer: 3, Epoch: 227 --- Error: 43.667610\n",
      "Layer: 3, Epoch: 228 --- Error: 43.048885\n",
      "Layer: 3, Epoch: 229 --- Error: 43.154366\n",
      "Layer: 3, Epoch: 230 --- Error: 43.180519\n",
      "Layer: 3, Epoch: 231 --- Error: 43.899353\n",
      "Layer: 3, Epoch: 232 --- Error: 43.061481\n",
      "Layer: 3, Epoch: 233 --- Error: 42.720383\n",
      "Layer: 3, Epoch: 234 --- Error: 42.690285\n",
      "Layer: 3, Epoch: 235 --- Error: 42.517838\n",
      "Layer: 3, Epoch: 236 --- Error: 42.602207\n",
      "Layer: 3, Epoch: 237 --- Error: 42.704216\n",
      "Layer: 3, Epoch: 238 --- Error: 42.816692\n",
      "Layer: 3, Epoch: 239 --- Error: 42.880650\n",
      "Layer: 3, Epoch: 240 --- Error: 42.437931\n",
      "Layer: 3, Epoch: 241 --- Error: 42.369984\n",
      "Layer: 3, Epoch: 242 --- Error: 42.395306\n",
      "Layer: 3, Epoch: 243 --- Error: 42.289909\n",
      "Layer: 3, Epoch: 244 --- Error: 42.144489\n",
      "Layer: 3, Epoch: 245 --- Error: 42.077030\n",
      "Layer: 3, Epoch: 246 --- Error: 42.162766\n",
      "Layer: 3, Epoch: 247 --- Error: 42.024555\n",
      "Layer: 3, Epoch: 248 --- Error: 41.896732\n",
      "Layer: 3, Epoch: 249 --- Error: 41.549660\n",
      "Layer: 3, Epoch: 250 --- Error: 41.319469\n",
      "Layer: 3, Epoch: 251 --- Error: 41.620224\n",
      "Layer: 3, Epoch: 252 --- Error: 41.404041\n",
      "Layer: 3, Epoch: 253 --- Error: 41.413517\n",
      "Layer: 3, Epoch: 254 --- Error: 41.280037\n",
      "Layer: 3, Epoch: 255 --- Error: 41.462925\n",
      "Layer: 3, Epoch: 256 --- Error: 41.008732\n",
      "Layer: 3, Epoch: 257 --- Error: 41.164021\n",
      "Layer: 3, Epoch: 258 --- Error: 40.886589\n",
      "Layer: 3, Epoch: 259 --- Error: 41.246193\n",
      "Layer: 3, Epoch: 260 --- Error: 40.654442\n",
      "Layer: 3, Epoch: 261 --- Error: 40.737942\n",
      "Layer: 3, Epoch: 262 --- Error: 40.868782\n",
      "Layer: 3, Epoch: 263 --- Error: 40.489235\n",
      "Layer: 3, Epoch: 264 --- Error: 40.250538\n",
      "Layer: 3, Epoch: 265 --- Error: 40.790146\n",
      "Layer: 3, Epoch: 266 --- Error: 40.339092\n",
      "Layer: 3, Epoch: 267 --- Error: 40.375359\n",
      "Layer: 3, Epoch: 268 --- Error: 40.583775\n",
      "Layer: 3, Epoch: 269 --- Error: 40.187397\n",
      "Layer: 3, Epoch: 270 --- Error: 40.309280\n",
      "Layer: 3, Epoch: 271 --- Error: 40.159969\n",
      "Layer: 3, Epoch: 272 --- Error: 39.955276\n",
      "Layer: 3, Epoch: 273 --- Error: 39.724220\n",
      "Layer: 3, Epoch: 274 --- Error: 40.178524\n",
      "Layer: 3, Epoch: 275 --- Error: 39.851585\n",
      "Layer: 3, Epoch: 276 --- Error: 39.453892\n",
      "Layer: 3, Epoch: 277 --- Error: 39.547184\n",
      "Layer: 3, Epoch: 278 --- Error: 39.511364\n",
      "Layer: 3, Epoch: 279 --- Error: 39.420341\n",
      "Layer: 3, Epoch: 280 --- Error: 39.284496\n",
      "Layer: 3, Epoch: 281 --- Error: 39.705025\n",
      "Layer: 3, Epoch: 282 --- Error: 39.182674\n",
      "Layer: 3, Epoch: 283 --- Error: 39.365612\n",
      "Layer: 3, Epoch: 284 --- Error: 39.401138\n",
      "Layer: 3, Epoch: 285 --- Error: 38.760056\n",
      "Layer: 3, Epoch: 286 --- Error: 39.555256\n",
      "Layer: 3, Epoch: 287 --- Error: 39.173428\n",
      "Layer: 3, Epoch: 288 --- Error: 38.591854\n",
      "Layer: 3, Epoch: 289 --- Error: 38.981689\n",
      "Layer: 3, Epoch: 290 --- Error: 38.752144\n",
      "Layer: 3, Epoch: 291 --- Error: 38.803097\n",
      "Layer: 3, Epoch: 292 --- Error: 38.949669\n",
      "Layer: 3, Epoch: 293 --- Error: 38.831215\n",
      "Layer: 3, Epoch: 294 --- Error: 38.788082\n",
      "Layer: 3, Epoch: 295 --- Error: 38.524429\n",
      "Layer: 3, Epoch: 296 --- Error: 38.516308\n",
      "Layer: 3, Epoch: 297 --- Error: 38.614029\n",
      "Layer: 3, Epoch: 298 --- Error: 38.409348\n",
      "Layer: 3, Epoch: 299 --- Error: 38.493797\n",
      "Layer: 3, Epoch: 300 --- Error: 38.746582\n",
      "Layer: 3, Epoch: 301 --- Error: 37.922203\n",
      "Layer: 3, Epoch: 302 --- Error: 38.219185\n",
      "Layer: 3, Epoch: 303 --- Error: 38.215836\n",
      "Layer: 3, Epoch: 304 --- Error: 37.893269\n",
      "Layer: 3, Epoch: 305 --- Error: 37.918545\n",
      "Layer: 3, Epoch: 306 --- Error: 38.273945\n",
      "Layer: 3, Epoch: 307 --- Error: 38.162376\n",
      "Layer: 3, Epoch: 308 --- Error: 37.853188\n",
      "Layer: 3, Epoch: 309 --- Error: 37.443363\n",
      "Layer: 3, Epoch: 310 --- Error: 37.903267\n",
      "Layer: 3, Epoch: 311 --- Error: 37.730167\n",
      "Layer: 3, Epoch: 312 --- Error: 37.188927\n",
      "Layer: 3, Epoch: 313 --- Error: 37.509338\n",
      "Layer: 3, Epoch: 314 --- Error: 38.276569\n",
      "Layer: 3, Epoch: 315 --- Error: 37.322338\n",
      "Layer: 3, Epoch: 316 --- Error: 37.628666\n",
      "Layer: 3, Epoch: 317 --- Error: 37.475574\n",
      "Layer: 3, Epoch: 318 --- Error: 37.176064\n",
      "Layer: 3, Epoch: 319 --- Error: 37.669384\n",
      "Layer: 3, Epoch: 320 --- Error: 37.316387\n",
      "Layer: 3, Epoch: 321 --- Error: 37.507561\n",
      "Layer: 3, Epoch: 322 --- Error: 36.745781\n",
      "Layer: 3, Epoch: 323 --- Error: 37.000919\n",
      "Layer: 3, Epoch: 324 --- Error: 36.973404\n",
      "Layer: 3, Epoch: 325 --- Error: 36.689503\n",
      "Layer: 3, Epoch: 326 --- Error: 37.356396\n",
      "Layer: 3, Epoch: 327 --- Error: 36.715984\n",
      "Layer: 3, Epoch: 328 --- Error: 36.960278\n",
      "Layer: 3, Epoch: 329 --- Error: 36.975906\n",
      "Layer: 3, Epoch: 330 --- Error: 36.815979\n",
      "Layer: 3, Epoch: 331 --- Error: 36.988232\n",
      "Layer: 3, Epoch: 332 --- Error: 36.938175\n",
      "Layer: 3, Epoch: 333 --- Error: 36.758949\n",
      "Layer: 3, Epoch: 334 --- Error: 36.597408\n",
      "Layer: 3, Epoch: 335 --- Error: 36.584251\n",
      "Layer: 3, Epoch: 336 --- Error: 36.803761\n",
      "Layer: 3, Epoch: 337 --- Error: 36.503342\n",
      "Layer: 3, Epoch: 338 --- Error: 36.713177\n",
      "Layer: 3, Epoch: 339 --- Error: 36.334743\n",
      "Layer: 3, Epoch: 340 --- Error: 36.269646\n",
      "Layer: 3, Epoch: 341 --- Error: 36.226734\n",
      "Layer: 3, Epoch: 342 --- Error: 36.174229\n",
      "Layer: 3, Epoch: 343 --- Error: 35.761093\n",
      "Layer: 3, Epoch: 344 --- Error: 36.156513\n",
      "Layer: 3, Epoch: 345 --- Error: 35.756908\n",
      "Layer: 3, Epoch: 346 --- Error: 36.046631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 3, Epoch: 347 --- Error: 36.075459\n",
      "Layer: 3, Epoch: 348 --- Error: 36.122623\n",
      "Layer: 3, Epoch: 349 --- Error: 35.511387\n",
      "Layer: 3, Epoch: 350 --- Error: 35.877125\n",
      "Layer: 3, Epoch: 351 --- Error: 35.668354\n",
      "Layer: 3, Epoch: 352 --- Error: 35.971737\n",
      "Layer: 3, Epoch: 353 --- Error: 35.746132\n",
      "Layer: 3, Epoch: 354 --- Error: 35.775070\n",
      "Layer: 3, Epoch: 355 --- Error: 35.843437\n",
      "Layer: 3, Epoch: 356 --- Error: 35.638409\n",
      "Layer: 3, Epoch: 357 --- Error: 36.154377\n",
      "Layer: 3, Epoch: 358 --- Error: 35.682774\n",
      "Layer: 3, Epoch: 359 --- Error: 35.289501\n",
      "Layer: 3, Epoch: 360 --- Error: 35.420876\n",
      "Layer: 3, Epoch: 361 --- Error: 35.328434\n",
      "Layer: 3, Epoch: 362 --- Error: 35.608807\n",
      "Layer: 3, Epoch: 363 --- Error: 35.622139\n",
      "Layer: 3, Epoch: 364 --- Error: 35.253315\n",
      "Layer: 3, Epoch: 365 --- Error: 35.325443\n",
      "Layer: 3, Epoch: 366 --- Error: 35.074940\n",
      "Layer: 3, Epoch: 367 --- Error: 35.244976\n",
      "Layer: 3, Epoch: 368 --- Error: 35.250736\n",
      "Layer: 3, Epoch: 369 --- Error: 35.198486\n",
      "Layer: 3, Epoch: 370 --- Error: 34.743206\n",
      "Layer: 3, Epoch: 371 --- Error: 35.031178\n",
      "Layer: 3, Epoch: 372 --- Error: 34.727234\n",
      "Layer: 3, Epoch: 373 --- Error: 34.851490\n",
      "Layer: 3, Epoch: 374 --- Error: 34.813206\n",
      "Layer: 3, Epoch: 375 --- Error: 35.126507\n",
      "Layer: 3, Epoch: 376 --- Error: 35.165134\n",
      "Layer: 3, Epoch: 377 --- Error: 34.889896\n",
      "Layer: 3, Epoch: 378 --- Error: 34.477886\n",
      "Layer: 3, Epoch: 379 --- Error: 34.586674\n",
      "Layer: 3, Epoch: 380 --- Error: 34.862720\n",
      "Layer: 3, Epoch: 381 --- Error: 34.699600\n",
      "Layer: 3, Epoch: 382 --- Error: 34.810078\n",
      "Layer: 3, Epoch: 383 --- Error: 34.471878\n",
      "Layer: 3, Epoch: 384 --- Error: 35.052998\n",
      "Layer: 3, Epoch: 385 --- Error: 34.538712\n",
      "Layer: 3, Epoch: 386 --- Error: 34.623497\n",
      "Layer: 3, Epoch: 387 --- Error: 33.909168\n",
      "Layer: 3, Epoch: 388 --- Error: 34.265369\n",
      "Layer: 3, Epoch: 389 --- Error: 34.481941\n",
      "Layer: 3, Epoch: 390 --- Error: 34.089428\n",
      "Layer: 3, Epoch: 391 --- Error: 34.199539\n",
      "Layer: 3, Epoch: 392 --- Error: 34.229721\n",
      "Layer: 3, Epoch: 393 --- Error: 33.970020\n",
      "Layer: 3, Epoch: 394 --- Error: 34.276562\n",
      "Layer: 3, Epoch: 395 --- Error: 33.948933\n",
      "Layer: 3, Epoch: 396 --- Error: 33.836811\n",
      "Layer: 3, Epoch: 397 --- Error: 33.881557\n",
      "Layer: 3, Epoch: 398 --- Error: 34.266186\n",
      "Layer: 3, Epoch: 399 --- Error: 34.473713\n",
      "Layer: 3, Epoch: 400 --- Error: 33.940342\n",
      "Layer: 3, Epoch: 401 --- Error: 33.960018\n",
      "Layer: 3, Epoch: 402 --- Error: 33.728279\n",
      "Layer: 3, Epoch: 403 --- Error: 33.780964\n",
      "Layer: 3, Epoch: 404 --- Error: 33.403278\n",
      "Layer: 3, Epoch: 405 --- Error: 33.731071\n",
      "Layer: 3, Epoch: 406 --- Error: 33.618122\n",
      "Layer: 3, Epoch: 407 --- Error: 33.764416\n",
      "Layer: 3, Epoch: 408 --- Error: 33.565083\n",
      "Layer: 3, Epoch: 409 --- Error: 33.737881\n",
      "Layer: 3, Epoch: 410 --- Error: 33.287331\n",
      "Layer: 3, Epoch: 411 --- Error: 33.971107\n",
      "Layer: 3, Epoch: 412 --- Error: 33.375973\n",
      "Layer: 3, Epoch: 413 --- Error: 33.822632\n",
      "Layer: 3, Epoch: 414 --- Error: 33.354977\n",
      "Layer: 3, Epoch: 415 --- Error: 33.461887\n",
      "Layer: 3, Epoch: 416 --- Error: 33.298389\n",
      "Layer: 3, Epoch: 417 --- Error: 33.444691\n",
      "Layer: 3, Epoch: 418 --- Error: 33.270969\n",
      "Layer: 3, Epoch: 419 --- Error: 33.021118\n",
      "Layer: 3, Epoch: 420 --- Error: 33.182510\n",
      "Layer: 3, Epoch: 421 --- Error: 33.126610\n",
      "Layer: 3, Epoch: 422 --- Error: 32.943527\n",
      "Layer: 3, Epoch: 423 --- Error: 33.220158\n",
      "Layer: 3, Epoch: 424 --- Error: 32.986008\n",
      "Layer: 3, Epoch: 425 --- Error: 32.895988\n",
      "Layer: 3, Epoch: 426 --- Error: 32.585335\n",
      "Layer: 3, Epoch: 427 --- Error: 33.243938\n",
      "Layer: 3, Epoch: 428 --- Error: 32.946461\n",
      "Layer: 3, Epoch: 429 --- Error: 33.059700\n",
      "Layer: 3, Epoch: 430 --- Error: 33.325283\n",
      "Layer: 3, Epoch: 431 --- Error: 33.113735\n",
      "Layer: 3, Epoch: 432 --- Error: 32.600800\n",
      "Layer: 3, Epoch: 433 --- Error: 33.026859\n",
      "Layer: 3, Epoch: 434 --- Error: 32.779629\n",
      "Layer: 3, Epoch: 435 --- Error: 32.661453\n",
      "Layer: 3, Epoch: 436 --- Error: 33.005478\n",
      "Layer: 3, Epoch: 437 --- Error: 32.593868\n",
      "Layer: 3, Epoch: 438 --- Error: 32.366535\n",
      "Layer: 3, Epoch: 439 --- Error: 32.841793\n",
      "Layer: 3, Epoch: 440 --- Error: 32.427483\n",
      "Layer: 3, Epoch: 441 --- Error: 32.397991\n",
      "Layer: 3, Epoch: 442 --- Error: 32.416744\n",
      "Layer: 3, Epoch: 443 --- Error: 32.591160\n",
      "Layer: 3, Epoch: 444 --- Error: 32.606018\n",
      "Layer: 3, Epoch: 445 --- Error: 32.658508\n",
      "Layer: 3, Epoch: 446 --- Error: 32.555946\n",
      "Layer: 3, Epoch: 447 --- Error: 32.625965\n",
      "Layer: 3, Epoch: 448 --- Error: 32.420677\n",
      "Layer: 3, Epoch: 449 --- Error: 32.686050\n",
      "Layer: 3, Epoch: 450 --- Error: 32.923367\n",
      "Layer: 3, Epoch: 451 --- Error: 32.746769\n",
      "Layer: 3, Epoch: 452 --- Error: 32.083397\n",
      "Layer: 3, Epoch: 453 --- Error: 32.141392\n",
      "Layer: 3, Epoch: 454 --- Error: 32.214909\n",
      "Layer: 3, Epoch: 455 --- Error: 32.014946\n",
      "Layer: 3, Epoch: 456 --- Error: 32.160118\n",
      "Layer: 3, Epoch: 457 --- Error: 32.120747\n",
      "Layer: 3, Epoch: 458 --- Error: 32.213051\n",
      "Layer: 3, Epoch: 459 --- Error: 32.072659\n",
      "Layer: 3, Epoch: 460 --- Error: 31.936729\n",
      "Layer: 3, Epoch: 461 --- Error: 31.985010\n",
      "Layer: 3, Epoch: 462 --- Error: 32.110065\n",
      "Layer: 3, Epoch: 463 --- Error: 31.796722\n",
      "Layer: 3, Epoch: 464 --- Error: 31.642462\n",
      "Layer: 3, Epoch: 465 --- Error: 32.028111\n",
      "Layer: 3, Epoch: 466 --- Error: 31.805920\n",
      "Layer: 3, Epoch: 467 --- Error: 31.892159\n",
      "Layer: 3, Epoch: 468 --- Error: 31.858114\n",
      "Layer: 3, Epoch: 469 --- Error: 31.779472\n",
      "Layer: 3, Epoch: 470 --- Error: 32.245903\n",
      "Layer: 3, Epoch: 471 --- Error: 31.902372\n",
      "Layer: 3, Epoch: 472 --- Error: 31.787535\n",
      "Layer: 3, Epoch: 473 --- Error: 31.721983\n",
      "Layer: 3, Epoch: 474 --- Error: 31.845268\n",
      "Layer: 3, Epoch: 475 --- Error: 31.607304\n",
      "Layer: 3, Epoch: 476 --- Error: 31.389458\n",
      "Layer: 3, Epoch: 477 --- Error: 31.439833\n",
      "Layer: 3, Epoch: 478 --- Error: 31.648291\n",
      "Layer: 3, Epoch: 479 --- Error: 31.651983\n",
      "Layer: 3, Epoch: 480 --- Error: 31.326727\n",
      "Layer: 3, Epoch: 481 --- Error: 31.517273\n",
      "Layer: 3, Epoch: 482 --- Error: 31.449427\n",
      "Layer: 3, Epoch: 483 --- Error: 31.846140\n",
      "Layer: 3, Epoch: 484 --- Error: 31.819563\n",
      "Layer: 3, Epoch: 485 --- Error: 31.601887\n",
      "Layer: 3, Epoch: 486 --- Error: 31.640608\n",
      "Layer: 3, Epoch: 487 --- Error: 31.204411\n",
      "Layer: 3, Epoch: 488 --- Error: 31.509073\n",
      "Layer: 3, Epoch: 489 --- Error: 31.639435\n",
      "Layer: 3, Epoch: 490 --- Error: 31.467121\n",
      "Layer: 3, Epoch: 491 --- Error: 31.290691\n",
      "Layer: 3, Epoch: 492 --- Error: 31.112728\n",
      "Layer: 3, Epoch: 493 --- Error: 31.269876\n",
      "Layer: 3, Epoch: 494 --- Error: 31.249666\n",
      "Layer: 3, Epoch: 495 --- Error: 31.301060\n",
      "Layer: 3, Epoch: 496 --- Error: 31.141043\n",
      "Layer: 3, Epoch: 497 --- Error: 31.053753\n",
      "Layer: 3, Epoch: 498 --- Error: 31.106958\n",
      "Layer: 3, Epoch: 499 --- Error: 30.975733\n",
      "Layer: 3, Epoch: 500 --- Error: 31.308674\n",
      "Epoch 0 out of 1000: --- Train loss 7.110446 --- Train accuracy 0.077778 --- valid f_score 0.111111\n",
      "Epoch 1 out of 1000: --- Train loss 6.408064 --- Train accuracy 0.277778 --- valid f_score 0.111111\n",
      "Epoch 2 out of 1000: --- Train loss 5.840075 --- Train accuracy 0.466667 --- valid f_score 0.151515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/luning/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 out of 1000: --- Train loss 5.364537 --- Train accuracy 0.522222 --- valid f_score 0.153846\n",
      "Epoch 4 out of 1000: --- Train loss 4.958547 --- Train accuracy 0.644444 --- valid f_score 0.300000\n",
      "Epoch 5 out of 1000: --- Train loss 4.607515 --- Train accuracy 0.655556 --- valid f_score 0.300000\n",
      "Epoch 6 out of 1000: --- Train loss 4.301392 --- Train accuracy 0.722222 --- valid f_score 0.278788\n",
      "Epoch 7 out of 1000: --- Train loss 4.032723 --- Train accuracy 0.755556 --- valid f_score 0.278788\n",
      "Epoch 8 out of 1000: --- Train loss 3.795639 --- Train accuracy 0.788889 --- valid f_score 0.278788\n",
      "Epoch 9 out of 1000: --- Train loss 3.585361 --- Train accuracy 0.811111 --- valid f_score 0.232323\n",
      "Epoch 10 out of 1000: --- Train loss 3.397934 --- Train accuracy 0.822222 --- valid f_score 0.232323\n",
      "Epoch 11 out of 1000: --- Train loss 3.230055 --- Train accuracy 0.833333 --- valid f_score 0.232323\n",
      "Epoch 12 out of 1000: --- Train loss 3.078997 --- Train accuracy 0.855556 --- valid f_score 0.232323\n",
      "Epoch 13 out of 1000: --- Train loss 2.942442 --- Train accuracy 0.866667 --- valid f_score 0.232323\n",
      "Epoch 14 out of 1000: --- Train loss 2.818453 --- Train accuracy 0.866667 --- valid f_score 0.232323\n",
      "Epoch 15 out of 1000: --- Train loss 2.705398 --- Train accuracy 0.866667 --- valid f_score 0.232323\n",
      "Epoch 16 out of 1000: --- Train loss 2.601896 --- Train accuracy 0.866667 --- valid f_score 0.232323\n",
      "Epoch 17 out of 1000: --- Train loss 2.506767 --- Train accuracy 0.877778 --- valid f_score 0.232323\n",
      "Epoch 18 out of 1000: --- Train loss 2.419021 --- Train accuracy 0.888889 --- valid f_score 0.232323\n",
      "Epoch 19 out of 1000: --- Train loss 2.337789 --- Train accuracy 0.888889 --- valid f_score 0.232323\n",
      "Epoch 20 out of 1000: --- Train loss 2.262352 --- Train accuracy 0.900000 --- valid f_score 0.232323\n",
      "Epoch 21 out of 1000: --- Train loss 2.192070 --- Train accuracy 0.900000 --- valid f_score 0.287879\n",
      "Epoch 22 out of 1000: --- Train loss 2.126393 --- Train accuracy 0.900000 --- valid f_score 0.287879\n",
      "Epoch 23 out of 1000: --- Train loss 2.064846 --- Train accuracy 0.911111 --- valid f_score 0.287879\n",
      "Epoch 24 out of 1000: --- Train loss 2.007017 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 25 out of 1000: --- Train loss 1.952543 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 26 out of 1000: --- Train loss 1.901109 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 27 out of 1000: --- Train loss 1.852429 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 28 out of 1000: --- Train loss 1.806274 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 29 out of 1000: --- Train loss 1.762402 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 30 out of 1000: --- Train loss 1.720656 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 31 out of 1000: --- Train loss 1.680850 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 32 out of 1000: --- Train loss 1.642832 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 33 out of 1000: --- Train loss 1.606466 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 34 out of 1000: --- Train loss 1.571632 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 35 out of 1000: --- Train loss 1.538220 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 36 out of 1000: --- Train loss 1.506134 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 37 out of 1000: --- Train loss 1.475283 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 38 out of 1000: --- Train loss 1.445590 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 39 out of 1000: --- Train loss 1.416981 --- Train accuracy 0.922222 --- valid f_score 0.287879\n",
      "Epoch 40 out of 1000: --- Train loss 1.389390 --- Train accuracy 0.922222 --- valid f_score 0.257143\n",
      "Epoch 41 out of 1000: --- Train loss 1.362759 --- Train accuracy 0.922222 --- valid f_score 0.257143\n",
      "Epoch 42 out of 1000: --- Train loss 1.337031 --- Train accuracy 0.933333 --- valid f_score 0.257143\n",
      "Epoch 43 out of 1000: --- Train loss 1.312158 --- Train accuracy 0.933333 --- valid f_score 0.257143\n",
      "Epoch 44 out of 1000: --- Train loss 1.288093 --- Train accuracy 0.933333 --- valid f_score 0.257143\n",
      "Epoch 45 out of 1000: --- Train loss 1.264794 --- Train accuracy 0.933333 --- valid f_score 0.257143\n",
      "Epoch 46 out of 1000: --- Train loss 1.242223 --- Train accuracy 0.933333 --- valid f_score 0.257143\n",
      "Epoch 47 out of 1000: --- Train loss 1.220343 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 48 out of 1000: --- Train loss 1.199122 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 49 out of 1000: --- Train loss 1.178527 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 50 out of 1000: --- Train loss 1.158532 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 51 out of 1000: --- Train loss 1.139108 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 52 out of 1000: --- Train loss 1.120231 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 53 out of 1000: --- Train loss 1.101878 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 54 out of 1000: --- Train loss 1.084026 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 55 out of 1000: --- Train loss 1.066655 --- Train accuracy 0.933333 --- valid f_score 0.272727\n",
      "Epoch 56 out of 1000: --- Train loss 1.049745 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 57 out of 1000: --- Train loss 1.033278 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 58 out of 1000: --- Train loss 1.017238 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 59 out of 1000: --- Train loss 1.001606 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 60 out of 1000: --- Train loss 0.986369 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 61 out of 1000: --- Train loss 0.971512 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 62 out of 1000: --- Train loss 0.957017 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 63 out of 1000: --- Train loss 0.942877 --- Train accuracy 0.944444 --- valid f_score 0.272727\n",
      "Epoch 64 out of 1000: --- Train loss 0.929077 --- Train accuracy 0.955556 --- valid f_score 0.272727\n",
      "Epoch 65 out of 1000: --- Train loss 0.915606 --- Train accuracy 0.955556 --- valid f_score 0.272727\n",
      "Epoch 66 out of 1000: --- Train loss 0.902451 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 67 out of 1000: --- Train loss 0.889602 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 68 out of 1000: --- Train loss 0.877049 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 69 out of 1000: --- Train loss 0.864782 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 70 out of 1000: --- Train loss 0.852791 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 71 out of 1000: --- Train loss 0.841068 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 72 out of 1000: --- Train loss 0.829602 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 73 out of 1000: --- Train loss 0.818389 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 74 out of 1000: --- Train loss 0.807419 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 75 out of 1000: --- Train loss 0.796685 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 76 out of 1000: --- Train loss 0.786179 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 77 out of 1000: --- Train loss 0.775894 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 78 out of 1000: --- Train loss 0.765823 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 79 out of 1000: --- Train loss 0.755961 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 80 out of 1000: --- Train loss 0.746300 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 81 out of 1000: --- Train loss 0.736836 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 82 out of 1000: --- Train loss 0.727562 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 83 out of 1000: --- Train loss 0.718472 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 84 out of 1000: --- Train loss 0.709562 --- Train accuracy 0.966667 --- valid f_score 0.272727\n",
      "Epoch 85 out of 1000: --- Train loss 0.700826 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 86 out of 1000: --- Train loss 0.692260 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 87 out of 1000: --- Train loss 0.683858 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 88 out of 1000: --- Train loss 0.675617 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 89 out of 1000: --- Train loss 0.667530 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 90 out of 1000: --- Train loss 0.659596 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 91 out of 1000: --- Train loss 0.651809 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 92 out of 1000: --- Train loss 0.644164 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 93 out of 1000: --- Train loss 0.636660 --- Train accuracy 0.977778 --- valid f_score 0.272727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 out of 1000: --- Train loss 0.629293 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 95 out of 1000: --- Train loss 0.622057 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 96 out of 1000: --- Train loss 0.614951 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 97 out of 1000: --- Train loss 0.607971 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 98 out of 1000: --- Train loss 0.601114 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 99 out of 1000: --- Train loss 0.594376 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 100 out of 1000: --- Train loss 0.587755 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 101 out of 1000: --- Train loss 0.581248 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 102 out of 1000: --- Train loss 0.574852 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 103 out of 1000: --- Train loss 0.568564 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 104 out of 1000: --- Train loss 0.562383 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 105 out of 1000: --- Train loss 0.556305 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 106 out of 1000: --- Train loss 0.550329 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 107 out of 1000: --- Train loss 0.544451 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 108 out of 1000: --- Train loss 0.538670 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 109 out of 1000: --- Train loss 0.532984 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 110 out of 1000: --- Train loss 0.527389 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 111 out of 1000: --- Train loss 0.521886 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 112 out of 1000: --- Train loss 0.516471 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 113 out of 1000: --- Train loss 0.511143 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 114 out of 1000: --- Train loss 0.505900 --- Train accuracy 0.977778 --- valid f_score 0.272727\n",
      "Epoch 115 out of 1000: --- Train loss 0.500740 --- Train accuracy 0.988889 --- valid f_score 0.272727\n",
      "Epoch 116 out of 1000: --- Train loss 0.495662 --- Train accuracy 0.988889 --- valid f_score 0.272727\n",
      "Epoch 117 out of 1000: --- Train loss 0.490663 --- Train accuracy 0.988889 --- valid f_score 0.272727\n",
      "Epoch 118 out of 1000: --- Train loss 0.485742 --- Train accuracy 0.988889 --- valid f_score 0.272727\n",
      "Epoch 119 out of 1000: --- Train loss 0.480898 --- Train accuracy 0.988889 --- valid f_score 0.272727\n",
      "Epoch 120 out of 1000: --- Train loss 0.476129 --- Train accuracy 0.988889 --- valid f_score 0.272727\n",
      "Epoch 121 out of 1000: --- Train loss 0.471434 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 122 out of 1000: --- Train loss 0.466811 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 123 out of 1000: --- Train loss 0.462258 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 124 out of 1000: --- Train loss 0.457775 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 125 out of 1000: --- Train loss 0.453361 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 126 out of 1000: --- Train loss 0.449013 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 127 out of 1000: --- Train loss 0.444730 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 128 out of 1000: --- Train loss 0.440512 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 129 out of 1000: --- Train loss 0.436357 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 130 out of 1000: --- Train loss 0.432264 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 131 out of 1000: --- Train loss 0.428232 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 132 out of 1000: --- Train loss 0.424260 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 133 out of 1000: --- Train loss 0.420347 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 134 out of 1000: --- Train loss 0.416491 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 135 out of 1000: --- Train loss 0.412692 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 136 out of 1000: --- Train loss 0.408948 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 137 out of 1000: --- Train loss 0.405259 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 138 out of 1000: --- Train loss 0.401624 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 139 out of 1000: --- Train loss 0.398041 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 140 out of 1000: --- Train loss 0.394510 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 141 out of 1000: --- Train loss 0.391030 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 142 out of 1000: --- Train loss 0.387601 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 143 out of 1000: --- Train loss 0.384220 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 144 out of 1000: --- Train loss 0.380887 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 145 out of 1000: --- Train loss 0.377602 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 146 out of 1000: --- Train loss 0.374364 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 147 out of 1000: --- Train loss 0.371172 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 148 out of 1000: --- Train loss 0.368024 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 149 out of 1000: --- Train loss 0.364921 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 150 out of 1000: --- Train loss 0.361861 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 151 out of 1000: --- Train loss 0.358844 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 152 out of 1000: --- Train loss 0.355870 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 153 out of 1000: --- Train loss 0.352936 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 154 out of 1000: --- Train loss 0.350043 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 155 out of 1000: --- Train loss 0.347190 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 156 out of 1000: --- Train loss 0.344376 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 157 out of 1000: --- Train loss 0.341601 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 158 out of 1000: --- Train loss 0.338864 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 159 out of 1000: --- Train loss 0.336164 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 160 out of 1000: --- Train loss 0.333500 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 161 out of 1000: --- Train loss 0.330873 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 162 out of 1000: --- Train loss 0.328281 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 163 out of 1000: --- Train loss 0.325723 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 164 out of 1000: --- Train loss 0.323200 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 165 out of 1000: --- Train loss 0.320711 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 166 out of 1000: --- Train loss 0.318254 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 167 out of 1000: --- Train loss 0.315830 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 168 out of 1000: --- Train loss 0.313438 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 169 out of 1000: --- Train loss 0.311078 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 170 out of 1000: --- Train loss 0.308748 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 171 out of 1000: --- Train loss 0.306448 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 172 out of 1000: --- Train loss 0.304179 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 173 out of 1000: --- Train loss 0.301938 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 174 out of 1000: --- Train loss 0.299727 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 175 out of 1000: --- Train loss 0.297543 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 176 out of 1000: --- Train loss 0.295388 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 177 out of 1000: --- Train loss 0.293260 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 178 out of 1000: --- Train loss 0.291159 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 179 out of 1000: --- Train loss 0.289084 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 180 out of 1000: --- Train loss 0.287036 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 181 out of 1000: --- Train loss 0.285013 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 182 out of 1000: --- Train loss 0.283015 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 183 out of 1000: --- Train loss 0.281042 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 184 out of 1000: --- Train loss 0.279093 --- Train accuracy 1.000000 --- valid f_score 0.272727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 out of 1000: --- Train loss 0.277168 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 186 out of 1000: --- Train loss 0.275267 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 187 out of 1000: --- Train loss 0.273389 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 188 out of 1000: --- Train loss 0.271533 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 189 out of 1000: --- Train loss 0.269700 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 190 out of 1000: --- Train loss 0.267890 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 191 out of 1000: --- Train loss 0.266100 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 192 out of 1000: --- Train loss 0.264332 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 193 out of 1000: --- Train loss 0.262586 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 194 out of 1000: --- Train loss 0.260859 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 195 out of 1000: --- Train loss 0.259153 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 196 out of 1000: --- Train loss 0.257467 --- Train accuracy 1.000000 --- valid f_score 0.272727\n",
      "Epoch 197 out of 1000: --- Train loss 0.255801 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 198 out of 1000: --- Train loss 0.254154 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 199 out of 1000: --- Train loss 0.252526 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 200 out of 1000: --- Train loss 0.250917 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 201 out of 1000: --- Train loss 0.249326 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 202 out of 1000: --- Train loss 0.247754 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 203 out of 1000: --- Train loss 0.246199 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 204 out of 1000: --- Train loss 0.244662 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 205 out of 1000: --- Train loss 0.243142 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 206 out of 1000: --- Train loss 0.241639 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 207 out of 1000: --- Train loss 0.240154 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 208 out of 1000: --- Train loss 0.238684 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 209 out of 1000: --- Train loss 0.237231 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 210 out of 1000: --- Train loss 0.235794 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 211 out of 1000: --- Train loss 0.234372 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 212 out of 1000: --- Train loss 0.232967 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 213 out of 1000: --- Train loss 0.231576 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 214 out of 1000: --- Train loss 0.230201 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 215 out of 1000: --- Train loss 0.228840 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 216 out of 1000: --- Train loss 0.227494 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 217 out of 1000: --- Train loss 0.226163 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 218 out of 1000: --- Train loss 0.224845 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 219 out of 1000: --- Train loss 0.223542 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 220 out of 1000: --- Train loss 0.222252 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 221 out of 1000: --- Train loss 0.220976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 222 out of 1000: --- Train loss 0.219714 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 223 out of 1000: --- Train loss 0.218464 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 224 out of 1000: --- Train loss 0.217228 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 225 out of 1000: --- Train loss 0.216004 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 226 out of 1000: --- Train loss 0.214793 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 227 out of 1000: --- Train loss 0.213594 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 228 out of 1000: --- Train loss 0.212408 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 229 out of 1000: --- Train loss 0.211233 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 230 out of 1000: --- Train loss 0.210071 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 231 out of 1000: --- Train loss 0.208920 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 232 out of 1000: --- Train loss 0.207781 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 233 out of 1000: --- Train loss 0.206653 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 234 out of 1000: --- Train loss 0.205537 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 235 out of 1000: --- Train loss 0.204431 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 236 out of 1000: --- Train loss 0.203337 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 237 out of 1000: --- Train loss 0.202253 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 238 out of 1000: --- Train loss 0.201180 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 239 out of 1000: --- Train loss 0.200117 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 240 out of 1000: --- Train loss 0.199065 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 241 out of 1000: --- Train loss 0.198022 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 242 out of 1000: --- Train loss 0.196990 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 243 out of 1000: --- Train loss 0.195968 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 244 out of 1000: --- Train loss 0.194956 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 245 out of 1000: --- Train loss 0.193953 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 246 out of 1000: --- Train loss 0.192960 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 247 out of 1000: --- Train loss 0.191976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 248 out of 1000: --- Train loss 0.191001 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 249 out of 1000: --- Train loss 0.190035 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 250 out of 1000: --- Train loss 0.189079 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 251 out of 1000: --- Train loss 0.188131 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 252 out of 1000: --- Train loss 0.187193 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 253 out of 1000: --- Train loss 0.186262 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 254 out of 1000: --- Train loss 0.185341 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 255 out of 1000: --- Train loss 0.184427 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 256 out of 1000: --- Train loss 0.183523 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 257 out of 1000: --- Train loss 0.182626 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 258 out of 1000: --- Train loss 0.181737 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 259 out of 1000: --- Train loss 0.180857 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 260 out of 1000: --- Train loss 0.179984 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 261 out of 1000: --- Train loss 0.179119 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 262 out of 1000: --- Train loss 0.178262 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 263 out of 1000: --- Train loss 0.177412 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 264 out of 1000: --- Train loss 0.176570 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 265 out of 1000: --- Train loss 0.175736 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 266 out of 1000: --- Train loss 0.174908 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 267 out of 1000: --- Train loss 0.174088 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 268 out of 1000: --- Train loss 0.173275 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 269 out of 1000: --- Train loss 0.172469 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 270 out of 1000: --- Train loss 0.171670 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 271 out of 1000: --- Train loss 0.170878 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 272 out of 1000: --- Train loss 0.170093 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 273 out of 1000: --- Train loss 0.169314 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 274 out of 1000: --- Train loss 0.168542 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 275 out of 1000: --- Train loss 0.167777 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276 out of 1000: --- Train loss 0.167017 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 277 out of 1000: --- Train loss 0.166265 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 278 out of 1000: --- Train loss 0.165518 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 279 out of 1000: --- Train loss 0.164778 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 280 out of 1000: --- Train loss 0.164044 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 281 out of 1000: --- Train loss 0.163316 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 282 out of 1000: --- Train loss 0.162594 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 283 out of 1000: --- Train loss 0.161878 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 284 out of 1000: --- Train loss 0.161168 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 285 out of 1000: --- Train loss 0.160464 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 286 out of 1000: --- Train loss 0.159765 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 287 out of 1000: --- Train loss 0.159072 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 288 out of 1000: --- Train loss 0.158385 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 289 out of 1000: --- Train loss 0.157703 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 290 out of 1000: --- Train loss 0.157026 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 291 out of 1000: --- Train loss 0.156355 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 292 out of 1000: --- Train loss 0.155690 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 293 out of 1000: --- Train loss 0.155029 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 294 out of 1000: --- Train loss 0.154374 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 295 out of 1000: --- Train loss 0.153724 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 296 out of 1000: --- Train loss 0.153079 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 297 out of 1000: --- Train loss 0.152439 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 298 out of 1000: --- Train loss 0.151804 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 299 out of 1000: --- Train loss 0.151174 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 300 out of 1000: --- Train loss 0.150549 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 301 out of 1000: --- Train loss 0.149929 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 302 out of 1000: --- Train loss 0.149313 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 303 out of 1000: --- Train loss 0.148702 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 304 out of 1000: --- Train loss 0.148096 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 305 out of 1000: --- Train loss 0.147494 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 306 out of 1000: --- Train loss 0.146897 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 307 out of 1000: --- Train loss 0.146304 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 308 out of 1000: --- Train loss 0.145716 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 309 out of 1000: --- Train loss 0.145133 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 310 out of 1000: --- Train loss 0.144553 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 311 out of 1000: --- Train loss 0.143978 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 312 out of 1000: --- Train loss 0.143407 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 313 out of 1000: --- Train loss 0.142840 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 314 out of 1000: --- Train loss 0.142278 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 315 out of 1000: --- Train loss 0.141720 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 316 out of 1000: --- Train loss 0.141165 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 317 out of 1000: --- Train loss 0.140615 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 318 out of 1000: --- Train loss 0.140069 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 319 out of 1000: --- Train loss 0.139527 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 320 out of 1000: --- Train loss 0.138988 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 321 out of 1000: --- Train loss 0.138454 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 322 out of 1000: --- Train loss 0.137923 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 323 out of 1000: --- Train loss 0.137396 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 324 out of 1000: --- Train loss 0.136873 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 325 out of 1000: --- Train loss 0.136353 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 326 out of 1000: --- Train loss 0.135837 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 327 out of 1000: --- Train loss 0.135325 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 328 out of 1000: --- Train loss 0.134817 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 329 out of 1000: --- Train loss 0.134312 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 330 out of 1000: --- Train loss 0.133810 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 331 out of 1000: --- Train loss 0.133312 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 332 out of 1000: --- Train loss 0.132818 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 333 out of 1000: --- Train loss 0.132326 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 334 out of 1000: --- Train loss 0.131839 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 335 out of 1000: --- Train loss 0.131354 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 336 out of 1000: --- Train loss 0.130873 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 337 out of 1000: --- Train loss 0.130395 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 338 out of 1000: --- Train loss 0.129920 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 339 out of 1000: --- Train loss 0.129449 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 340 out of 1000: --- Train loss 0.128981 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 341 out of 1000: --- Train loss 0.128516 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 342 out of 1000: --- Train loss 0.128054 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 343 out of 1000: --- Train loss 0.127595 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 344 out of 1000: --- Train loss 0.127139 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 345 out of 1000: --- Train loss 0.126686 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 346 out of 1000: --- Train loss 0.126236 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 347 out of 1000: --- Train loss 0.125789 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 348 out of 1000: --- Train loss 0.125345 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 349 out of 1000: --- Train loss 0.124904 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 350 out of 1000: --- Train loss 0.124466 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 351 out of 1000: --- Train loss 0.124031 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 352 out of 1000: --- Train loss 0.123599 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 353 out of 1000: --- Train loss 0.123169 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 354 out of 1000: --- Train loss 0.122742 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 355 out of 1000: --- Train loss 0.122318 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 356 out of 1000: --- Train loss 0.121896 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 357 out of 1000: --- Train loss 0.121478 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 358 out of 1000: --- Train loss 0.121062 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 359 out of 1000: --- Train loss 0.120648 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 360 out of 1000: --- Train loss 0.120237 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 361 out of 1000: --- Train loss 0.119829 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 362 out of 1000: --- Train loss 0.119424 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 363 out of 1000: --- Train loss 0.119020 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364 out of 1000: --- Train loss 0.118620 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 365 out of 1000: --- Train loss 0.118222 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 366 out of 1000: --- Train loss 0.117826 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 367 out of 1000: --- Train loss 0.117433 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 368 out of 1000: --- Train loss 0.117042 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 369 out of 1000: --- Train loss 0.116654 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 370 out of 1000: --- Train loss 0.116268 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 371 out of 1000: --- Train loss 0.115884 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 372 out of 1000: --- Train loss 0.115503 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 373 out of 1000: --- Train loss 0.115124 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 374 out of 1000: --- Train loss 0.114748 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 375 out of 1000: --- Train loss 0.114373 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 376 out of 1000: --- Train loss 0.114001 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 377 out of 1000: --- Train loss 0.113631 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 378 out of 1000: --- Train loss 0.113264 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 379 out of 1000: --- Train loss 0.112898 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 380 out of 1000: --- Train loss 0.112535 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 381 out of 1000: --- Train loss 0.112174 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 382 out of 1000: --- Train loss 0.111815 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 383 out of 1000: --- Train loss 0.111458 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 384 out of 1000: --- Train loss 0.111104 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 385 out of 1000: --- Train loss 0.110751 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 386 out of 1000: --- Train loss 0.110400 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 387 out of 1000: --- Train loss 0.110052 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 388 out of 1000: --- Train loss 0.109705 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 389 out of 1000: --- Train loss 0.109361 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 390 out of 1000: --- Train loss 0.109018 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 391 out of 1000: --- Train loss 0.108678 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 392 out of 1000: --- Train loss 0.108339 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 393 out of 1000: --- Train loss 0.108003 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 394 out of 1000: --- Train loss 0.107668 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 395 out of 1000: --- Train loss 0.107335 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 396 out of 1000: --- Train loss 0.107004 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 397 out of 1000: --- Train loss 0.106675 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 398 out of 1000: --- Train loss 0.106348 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 399 out of 1000: --- Train loss 0.106023 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 400 out of 1000: --- Train loss 0.105699 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 401 out of 1000: --- Train loss 0.105378 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 402 out of 1000: --- Train loss 0.105058 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 403 out of 1000: --- Train loss 0.104740 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 404 out of 1000: --- Train loss 0.104424 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 405 out of 1000: --- Train loss 0.104109 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 406 out of 1000: --- Train loss 0.103796 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 407 out of 1000: --- Train loss 0.103485 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 408 out of 1000: --- Train loss 0.103176 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 409 out of 1000: --- Train loss 0.102868 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 410 out of 1000: --- Train loss 0.102562 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 411 out of 1000: --- Train loss 0.102258 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 412 out of 1000: --- Train loss 0.101955 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 413 out of 1000: --- Train loss 0.101654 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 414 out of 1000: --- Train loss 0.101355 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 415 out of 1000: --- Train loss 0.101057 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 416 out of 1000: --- Train loss 0.100761 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 417 out of 1000: --- Train loss 0.100466 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 418 out of 1000: --- Train loss 0.100173 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 419 out of 1000: --- Train loss 0.099882 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 420 out of 1000: --- Train loss 0.099592 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 421 out of 1000: --- Train loss 0.099304 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 422 out of 1000: --- Train loss 0.099017 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 423 out of 1000: --- Train loss 0.098732 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 424 out of 1000: --- Train loss 0.098448 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 425 out of 1000: --- Train loss 0.098166 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 426 out of 1000: --- Train loss 0.097885 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 427 out of 1000: --- Train loss 0.097605 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 428 out of 1000: --- Train loss 0.097328 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 429 out of 1000: --- Train loss 0.097051 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 430 out of 1000: --- Train loss 0.096776 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 431 out of 1000: --- Train loss 0.096502 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 432 out of 1000: --- Train loss 0.096230 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 433 out of 1000: --- Train loss 0.095959 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 434 out of 1000: --- Train loss 0.095690 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 435 out of 1000: --- Train loss 0.095422 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 436 out of 1000: --- Train loss 0.095155 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 437 out of 1000: --- Train loss 0.094890 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 438 out of 1000: --- Train loss 0.094626 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 439 out of 1000: --- Train loss 0.094364 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 440 out of 1000: --- Train loss 0.094102 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 441 out of 1000: --- Train loss 0.093842 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 442 out of 1000: --- Train loss 0.093584 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 443 out of 1000: --- Train loss 0.093326 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 444 out of 1000: --- Train loss 0.093070 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 445 out of 1000: --- Train loss 0.092815 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 446 out of 1000: --- Train loss 0.092562 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 447 out of 1000: --- Train loss 0.092310 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 448 out of 1000: --- Train loss 0.092059 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 449 out of 1000: --- Train loss 0.091809 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 450 out of 1000: --- Train loss 0.091560 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 451 out of 1000: --- Train loss 0.091313 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 452 out of 1000: --- Train loss 0.091067 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 453 out of 1000: --- Train loss 0.090822 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 454 out of 1000: --- Train loss 0.090578 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 455 out of 1000: --- Train loss 0.090335 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 456 out of 1000: --- Train loss 0.090094 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 457 out of 1000: --- Train loss 0.089854 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 458 out of 1000: --- Train loss 0.089615 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 459 out of 1000: --- Train loss 0.089377 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460 out of 1000: --- Train loss 0.089140 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 461 out of 1000: --- Train loss 0.088905 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 462 out of 1000: --- Train loss 0.088670 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 463 out of 1000: --- Train loss 0.088437 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 464 out of 1000: --- Train loss 0.088204 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 465 out of 1000: --- Train loss 0.087973 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 466 out of 1000: --- Train loss 0.087743 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 467 out of 1000: --- Train loss 0.087514 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 468 out of 1000: --- Train loss 0.087286 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 469 out of 1000: --- Train loss 0.087060 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 470 out of 1000: --- Train loss 0.086834 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 471 out of 1000: --- Train loss 0.086609 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 472 out of 1000: --- Train loss 0.086385 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 473 out of 1000: --- Train loss 0.086163 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 474 out of 1000: --- Train loss 0.085941 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 475 out of 1000: --- Train loss 0.085721 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 476 out of 1000: --- Train loss 0.085501 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 477 out of 1000: --- Train loss 0.085283 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 478 out of 1000: --- Train loss 0.085065 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 479 out of 1000: --- Train loss 0.084849 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 480 out of 1000: --- Train loss 0.084633 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 481 out of 1000: --- Train loss 0.084419 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 482 out of 1000: --- Train loss 0.084205 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 483 out of 1000: --- Train loss 0.083992 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 484 out of 1000: --- Train loss 0.083781 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 485 out of 1000: --- Train loss 0.083570 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 486 out of 1000: --- Train loss 0.083360 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 487 out of 1000: --- Train loss 0.083152 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 488 out of 1000: --- Train loss 0.082944 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 489 out of 1000: --- Train loss 0.082737 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 490 out of 1000: --- Train loss 0.082531 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 491 out of 1000: --- Train loss 0.082326 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 492 out of 1000: --- Train loss 0.082122 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 493 out of 1000: --- Train loss 0.081919 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 494 out of 1000: --- Train loss 0.081716 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 495 out of 1000: --- Train loss 0.081515 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 496 out of 1000: --- Train loss 0.081315 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 497 out of 1000: --- Train loss 0.081115 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 498 out of 1000: --- Train loss 0.080916 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 499 out of 1000: --- Train loss 0.080718 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 500 out of 1000: --- Train loss 0.080521 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 501 out of 1000: --- Train loss 0.080325 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 502 out of 1000: --- Train loss 0.080130 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 503 out of 1000: --- Train loss 0.079936 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 504 out of 1000: --- Train loss 0.079742 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 505 out of 1000: --- Train loss 0.079549 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 506 out of 1000: --- Train loss 0.079357 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 507 out of 1000: --- Train loss 0.079166 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 508 out of 1000: --- Train loss 0.078976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 509 out of 1000: --- Train loss 0.078787 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 510 out of 1000: --- Train loss 0.078598 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 511 out of 1000: --- Train loss 0.078410 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 512 out of 1000: --- Train loss 0.078223 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 513 out of 1000: --- Train loss 0.078037 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 514 out of 1000: --- Train loss 0.077852 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 515 out of 1000: --- Train loss 0.077667 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 516 out of 1000: --- Train loss 0.077483 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 517 out of 1000: --- Train loss 0.077300 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 518 out of 1000: --- Train loss 0.077118 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 519 out of 1000: --- Train loss 0.076937 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 520 out of 1000: --- Train loss 0.076756 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 521 out of 1000: --- Train loss 0.076576 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 522 out of 1000: --- Train loss 0.076397 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 523 out of 1000: --- Train loss 0.076219 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 524 out of 1000: --- Train loss 0.076041 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 525 out of 1000: --- Train loss 0.075864 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 526 out of 1000: --- Train loss 0.075688 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 527 out of 1000: --- Train loss 0.075512 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 528 out of 1000: --- Train loss 0.075338 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 529 out of 1000: --- Train loss 0.075164 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 530 out of 1000: --- Train loss 0.074991 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 531 out of 1000: --- Train loss 0.074818 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 532 out of 1000: --- Train loss 0.074646 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 533 out of 1000: --- Train loss 0.074475 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 534 out of 1000: --- Train loss 0.074305 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 535 out of 1000: --- Train loss 0.074135 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 536 out of 1000: --- Train loss 0.073966 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 537 out of 1000: --- Train loss 0.073798 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 538 out of 1000: --- Train loss 0.073630 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 539 out of 1000: --- Train loss 0.073463 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 540 out of 1000: --- Train loss 0.073297 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 541 out of 1000: --- Train loss 0.073132 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 542 out of 1000: --- Train loss 0.072967 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 543 out of 1000: --- Train loss 0.072802 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 544 out of 1000: --- Train loss 0.072639 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 545 out of 1000: --- Train loss 0.072476 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 546 out of 1000: --- Train loss 0.072314 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 547 out of 1000: --- Train loss 0.072153 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 548 out of 1000: --- Train loss 0.071992 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 549 out of 1000: --- Train loss 0.071831 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 550 out of 1000: --- Train loss 0.071672 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 551 out of 1000: --- Train loss 0.071513 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 552 out of 1000: --- Train loss 0.071355 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 553 out of 1000: --- Train loss 0.071197 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 554 out of 1000: --- Train loss 0.071040 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 555 out of 1000: --- Train loss 0.070884 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 556 out of 1000: --- Train loss 0.070728 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 557 out of 1000: --- Train loss 0.070573 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 558 out of 1000: --- Train loss 0.070418 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 559 out of 1000: --- Train loss 0.070264 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560 out of 1000: --- Train loss 0.070111 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 561 out of 1000: --- Train loss 0.069958 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 562 out of 1000: --- Train loss 0.069806 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 563 out of 1000: --- Train loss 0.069655 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 564 out of 1000: --- Train loss 0.069504 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 565 out of 1000: --- Train loss 0.069354 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 566 out of 1000: --- Train loss 0.069204 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 567 out of 1000: --- Train loss 0.069055 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 568 out of 1000: --- Train loss 0.068907 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 569 out of 1000: --- Train loss 0.068759 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 570 out of 1000: --- Train loss 0.068611 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 571 out of 1000: --- Train loss 0.068465 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 572 out of 1000: --- Train loss 0.068319 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 573 out of 1000: --- Train loss 0.068173 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 574 out of 1000: --- Train loss 0.068028 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 575 out of 1000: --- Train loss 0.067883 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 576 out of 1000: --- Train loss 0.067740 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 577 out of 1000: --- Train loss 0.067596 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 578 out of 1000: --- Train loss 0.067454 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 579 out of 1000: --- Train loss 0.067311 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 580 out of 1000: --- Train loss 0.067170 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 581 out of 1000: --- Train loss 0.067029 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 582 out of 1000: --- Train loss 0.066888 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 583 out of 1000: --- Train loss 0.066748 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 584 out of 1000: --- Train loss 0.066609 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 585 out of 1000: --- Train loss 0.066470 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 586 out of 1000: --- Train loss 0.066331 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 587 out of 1000: --- Train loss 0.066193 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 588 out of 1000: --- Train loss 0.066056 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 589 out of 1000: --- Train loss 0.065919 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 590 out of 1000: --- Train loss 0.065783 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 591 out of 1000: --- Train loss 0.065647 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 592 out of 1000: --- Train loss 0.065512 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 593 out of 1000: --- Train loss 0.065377 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 594 out of 1000: --- Train loss 0.065243 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 595 out of 1000: --- Train loss 0.065109 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 596 out of 1000: --- Train loss 0.064976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 597 out of 1000: --- Train loss 0.064844 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 598 out of 1000: --- Train loss 0.064711 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 599 out of 1000: --- Train loss 0.064580 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 600 out of 1000: --- Train loss 0.064449 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 601 out of 1000: --- Train loss 0.064318 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 602 out of 1000: --- Train loss 0.064188 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 603 out of 1000: --- Train loss 0.064058 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 604 out of 1000: --- Train loss 0.063929 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 605 out of 1000: --- Train loss 0.063800 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 606 out of 1000: --- Train loss 0.063672 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 607 out of 1000: --- Train loss 0.063544 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 608 out of 1000: --- Train loss 0.063417 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 609 out of 1000: --- Train loss 0.063290 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 610 out of 1000: --- Train loss 0.063164 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 611 out of 1000: --- Train loss 0.063038 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 612 out of 1000: --- Train loss 0.062913 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 613 out of 1000: --- Train loss 0.062788 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 614 out of 1000: --- Train loss 0.062663 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 615 out of 1000: --- Train loss 0.062539 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 616 out of 1000: --- Train loss 0.062416 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 617 out of 1000: --- Train loss 0.062293 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 618 out of 1000: --- Train loss 0.062170 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 619 out of 1000: --- Train loss 0.062048 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 620 out of 1000: --- Train loss 0.061926 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 621 out of 1000: --- Train loss 0.061805 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 622 out of 1000: --- Train loss 0.061684 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 623 out of 1000: --- Train loss 0.061564 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 624 out of 1000: --- Train loss 0.061444 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 625 out of 1000: --- Train loss 0.061324 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 626 out of 1000: --- Train loss 0.061205 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 627 out of 1000: --- Train loss 0.061087 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 628 out of 1000: --- Train loss 0.060968 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 629 out of 1000: --- Train loss 0.060851 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 630 out of 1000: --- Train loss 0.060733 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 631 out of 1000: --- Train loss 0.060616 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 632 out of 1000: --- Train loss 0.060500 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 633 out of 1000: --- Train loss 0.060384 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 634 out of 1000: --- Train loss 0.060268 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 635 out of 1000: --- Train loss 0.060153 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 636 out of 1000: --- Train loss 0.060038 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 637 out of 1000: --- Train loss 0.059924 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 638 out of 1000: --- Train loss 0.059810 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 639 out of 1000: --- Train loss 0.059696 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 640 out of 1000: --- Train loss 0.059583 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 641 out of 1000: --- Train loss 0.059470 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 642 out of 1000: --- Train loss 0.059358 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 643 out of 1000: --- Train loss 0.059246 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 644 out of 1000: --- Train loss 0.059134 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 645 out of 1000: --- Train loss 0.059023 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 646 out of 1000: --- Train loss 0.058912 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 647 out of 1000: --- Train loss 0.058802 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 648 out of 1000: --- Train loss 0.058692 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 649 out of 1000: --- Train loss 0.058582 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 650 out of 1000: --- Train loss 0.058473 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 651 out of 1000: --- Train loss 0.058364 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 652 out of 1000: --- Train loss 0.058256 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 653 out of 1000: --- Train loss 0.058148 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 654 out of 1000: --- Train loss 0.058040 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 655 out of 1000: --- Train loss 0.057933 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 656 out of 1000: --- Train loss 0.057826 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 657 out of 1000: --- Train loss 0.057719 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 658 out of 1000: --- Train loss 0.057613 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 659 out of 1000: --- Train loss 0.057507 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 660 out of 1000: --- Train loss 0.057402 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 661 out of 1000: --- Train loss 0.057297 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 662 out of 1000: --- Train loss 0.057192 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 663 out of 1000: --- Train loss 0.057088 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 664 out of 1000: --- Train loss 0.056984 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 665 out of 1000: --- Train loss 0.056880 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 666 out of 1000: --- Train loss 0.056777 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 667 out of 1000: --- Train loss 0.056674 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 668 out of 1000: --- Train loss 0.056571 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 669 out of 1000: --- Train loss 0.056469 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 670 out of 1000: --- Train loss 0.056367 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 671 out of 1000: --- Train loss 0.056266 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 672 out of 1000: --- Train loss 0.056164 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 673 out of 1000: --- Train loss 0.056064 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 674 out of 1000: --- Train loss 0.055963 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 675 out of 1000: --- Train loss 0.055863 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 676 out of 1000: --- Train loss 0.055763 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 677 out of 1000: --- Train loss 0.055664 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 678 out of 1000: --- Train loss 0.055564 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 679 out of 1000: --- Train loss 0.055466 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 680 out of 1000: --- Train loss 0.055367 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 681 out of 1000: --- Train loss 0.055269 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 682 out of 1000: --- Train loss 0.055171 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 683 out of 1000: --- Train loss 0.055074 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 684 out of 1000: --- Train loss 0.054976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 685 out of 1000: --- Train loss 0.054880 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 686 out of 1000: --- Train loss 0.054783 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 687 out of 1000: --- Train loss 0.054687 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 688 out of 1000: --- Train loss 0.054591 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 689 out of 1000: --- Train loss 0.054496 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 690 out of 1000: --- Train loss 0.054400 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 691 out of 1000: --- Train loss 0.054305 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 692 out of 1000: --- Train loss 0.054211 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 693 out of 1000: --- Train loss 0.054116 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 694 out of 1000: --- Train loss 0.054022 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 695 out of 1000: --- Train loss 0.053929 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 696 out of 1000: --- Train loss 0.053835 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 697 out of 1000: --- Train loss 0.053742 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 698 out of 1000: --- Train loss 0.053650 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 699 out of 1000: --- Train loss 0.053557 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 700 out of 1000: --- Train loss 0.053465 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 701 out of 1000: --- Train loss 0.053373 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 702 out of 1000: --- Train loss 0.053282 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 703 out of 1000: --- Train loss 0.053190 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 704 out of 1000: --- Train loss 0.053099 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 705 out of 1000: --- Train loss 0.053009 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 706 out of 1000: --- Train loss 0.052918 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 707 out of 1000: --- Train loss 0.052828 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 708 out of 1000: --- Train loss 0.052738 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 709 out of 1000: --- Train loss 0.052649 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 710 out of 1000: --- Train loss 0.052560 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 711 out of 1000: --- Train loss 0.052471 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 712 out of 1000: --- Train loss 0.052382 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 713 out of 1000: --- Train loss 0.052294 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 714 out of 1000: --- Train loss 0.052206 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 715 out of 1000: --- Train loss 0.052118 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 716 out of 1000: --- Train loss 0.052030 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 717 out of 1000: --- Train loss 0.051943 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 718 out of 1000: --- Train loss 0.051856 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 719 out of 1000: --- Train loss 0.051769 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 720 out of 1000: --- Train loss 0.051683 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 721 out of 1000: --- Train loss 0.051597 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 722 out of 1000: --- Train loss 0.051511 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 723 out of 1000: --- Train loss 0.051425 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 724 out of 1000: --- Train loss 0.051340 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 725 out of 1000: --- Train loss 0.051255 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 726 out of 1000: --- Train loss 0.051170 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 727 out of 1000: --- Train loss 0.051085 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 728 out of 1000: --- Train loss 0.051001 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 729 out of 1000: --- Train loss 0.050917 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 730 out of 1000: --- Train loss 0.050833 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 731 out of 1000: --- Train loss 0.050750 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 732 out of 1000: --- Train loss 0.050667 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 733 out of 1000: --- Train loss 0.050584 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 734 out of 1000: --- Train loss 0.050501 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 735 out of 1000: --- Train loss 0.050418 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 736 out of 1000: --- Train loss 0.050336 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 737 out of 1000: --- Train loss 0.050254 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 738 out of 1000: --- Train loss 0.050173 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 739 out of 1000: --- Train loss 0.050091 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 740 out of 1000: --- Train loss 0.050010 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 741 out of 1000: --- Train loss 0.049929 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 742 out of 1000: --- Train loss 0.049848 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 743 out of 1000: --- Train loss 0.049768 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 744 out of 1000: --- Train loss 0.049688 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 745 out of 1000: --- Train loss 0.049608 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 746 out of 1000: --- Train loss 0.049528 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 747 out of 1000: --- Train loss 0.049448 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 748 out of 1000: --- Train loss 0.049369 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 749 out of 1000: --- Train loss 0.049290 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 750 out of 1000: --- Train loss 0.049211 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 751 out of 1000: --- Train loss 0.049133 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 752 out of 1000: --- Train loss 0.049055 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 753 out of 1000: --- Train loss 0.048976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 754 out of 1000: --- Train loss 0.048899 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 755 out of 1000: --- Train loss 0.048821 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 756 out of 1000: --- Train loss 0.048744 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 757 out of 1000: --- Train loss 0.048667 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 758 out of 1000: --- Train loss 0.048590 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 759 out of 1000: --- Train loss 0.048513 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 760 out of 1000: --- Train loss 0.048437 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 761 out of 1000: --- Train loss 0.048360 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 762 out of 1000: --- Train loss 0.048284 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 763 out of 1000: --- Train loss 0.048209 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 764 out of 1000: --- Train loss 0.048133 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 765 out of 1000: --- Train loss 0.048058 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 766 out of 1000: --- Train loss 0.047983 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 767 out of 1000: --- Train loss 0.047908 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 768 out of 1000: --- Train loss 0.047833 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 769 out of 1000: --- Train loss 0.047759 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 770 out of 1000: --- Train loss 0.047684 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 771 out of 1000: --- Train loss 0.047610 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 772 out of 1000: --- Train loss 0.047537 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 773 out of 1000: --- Train loss 0.047463 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 774 out of 1000: --- Train loss 0.047390 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 775 out of 1000: --- Train loss 0.047317 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 776 out of 1000: --- Train loss 0.047244 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 777 out of 1000: --- Train loss 0.047171 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 778 out of 1000: --- Train loss 0.047098 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 779 out of 1000: --- Train loss 0.047026 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 780 out of 1000: --- Train loss 0.046954 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 781 out of 1000: --- Train loss 0.046882 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 782 out of 1000: --- Train loss 0.046811 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 783 out of 1000: --- Train loss 0.046739 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 784 out of 1000: --- Train loss 0.046668 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 785 out of 1000: --- Train loss 0.046597 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 786 out of 1000: --- Train loss 0.046526 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 787 out of 1000: --- Train loss 0.046455 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 788 out of 1000: --- Train loss 0.046385 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 789 out of 1000: --- Train loss 0.046315 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 790 out of 1000: --- Train loss 0.046245 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 791 out of 1000: --- Train loss 0.046175 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 792 out of 1000: --- Train loss 0.046105 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 793 out of 1000: --- Train loss 0.046036 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 794 out of 1000: --- Train loss 0.045966 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 795 out of 1000: --- Train loss 0.045897 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 796 out of 1000: --- Train loss 0.045828 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 797 out of 1000: --- Train loss 0.045760 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 798 out of 1000: --- Train loss 0.045691 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 799 out of 1000: --- Train loss 0.045623 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 800 out of 1000: --- Train loss 0.045555 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 801 out of 1000: --- Train loss 0.045487 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 802 out of 1000: --- Train loss 0.045419 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 803 out of 1000: --- Train loss 0.045352 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 804 out of 1000: --- Train loss 0.045284 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 805 out of 1000: --- Train loss 0.045217 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 806 out of 1000: --- Train loss 0.045150 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 807 out of 1000: --- Train loss 0.045084 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 808 out of 1000: --- Train loss 0.045017 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 809 out of 1000: --- Train loss 0.044951 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 810 out of 1000: --- Train loss 0.044884 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 811 out of 1000: --- Train loss 0.044818 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 812 out of 1000: --- Train loss 0.044752 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 813 out of 1000: --- Train loss 0.044687 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 814 out of 1000: --- Train loss 0.044621 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 815 out of 1000: --- Train loss 0.044556 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 816 out of 1000: --- Train loss 0.044491 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 817 out of 1000: --- Train loss 0.044426 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 818 out of 1000: --- Train loss 0.044361 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 819 out of 1000: --- Train loss 0.044297 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 820 out of 1000: --- Train loss 0.044232 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 821 out of 1000: --- Train loss 0.044168 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 822 out of 1000: --- Train loss 0.044104 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 823 out of 1000: --- Train loss 0.044040 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 824 out of 1000: --- Train loss 0.043976 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 825 out of 1000: --- Train loss 0.043913 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 826 out of 1000: --- Train loss 0.043849 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 827 out of 1000: --- Train loss 0.043786 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 828 out of 1000: --- Train loss 0.043723 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 829 out of 1000: --- Train loss 0.043660 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 830 out of 1000: --- Train loss 0.043598 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 831 out of 1000: --- Train loss 0.043535 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 832 out of 1000: --- Train loss 0.043473 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 833 out of 1000: --- Train loss 0.043411 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 834 out of 1000: --- Train loss 0.043349 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 835 out of 1000: --- Train loss 0.043287 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 836 out of 1000: --- Train loss 0.043225 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 837 out of 1000: --- Train loss 0.043163 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 838 out of 1000: --- Train loss 0.043102 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 839 out of 1000: --- Train loss 0.043041 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 840 out of 1000: --- Train loss 0.042980 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 841 out of 1000: --- Train loss 0.042919 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 842 out of 1000: --- Train loss 0.042858 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 843 out of 1000: --- Train loss 0.042798 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 844 out of 1000: --- Train loss 0.042737 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 845 out of 1000: --- Train loss 0.042677 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 846 out of 1000: --- Train loss 0.042617 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 847 out of 1000: --- Train loss 0.042557 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 848 out of 1000: --- Train loss 0.042497 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 849 out of 1000: --- Train loss 0.042438 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 850 out of 1000: --- Train loss 0.042378 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 851 out of 1000: --- Train loss 0.042319 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 852 out of 1000: --- Train loss 0.042260 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 853 out of 1000: --- Train loss 0.042201 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 854 out of 1000: --- Train loss 0.042142 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 855 out of 1000: --- Train loss 0.042084 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 856 out of 1000: --- Train loss 0.042025 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 857 out of 1000: --- Train loss 0.041967 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 858 out of 1000: --- Train loss 0.041909 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 859 out of 1000: --- Train loss 0.041851 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 860 out of 1000: --- Train loss 0.041793 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 861 out of 1000: --- Train loss 0.041735 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 862 out of 1000: --- Train loss 0.041677 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 863 out of 1000: --- Train loss 0.041620 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 864 out of 1000: --- Train loss 0.041563 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 865 out of 1000: --- Train loss 0.041505 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 866 out of 1000: --- Train loss 0.041448 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 867 out of 1000: --- Train loss 0.041392 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 868 out of 1000: --- Train loss 0.041335 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 869 out of 1000: --- Train loss 0.041278 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 870 out of 1000: --- Train loss 0.041222 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 871 out of 1000: --- Train loss 0.041166 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 872 out of 1000: --- Train loss 0.041110 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 873 out of 1000: --- Train loss 0.041054 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 874 out of 1000: --- Train loss 0.040998 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 875 out of 1000: --- Train loss 0.040942 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 876 out of 1000: --- Train loss 0.040887 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 877 out of 1000: --- Train loss 0.040831 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 878 out of 1000: --- Train loss 0.040776 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 879 out of 1000: --- Train loss 0.040721 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 880 out of 1000: --- Train loss 0.040666 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 881 out of 1000: --- Train loss 0.040611 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 882 out of 1000: --- Train loss 0.040556 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 883 out of 1000: --- Train loss 0.040502 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 884 out of 1000: --- Train loss 0.040447 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 885 out of 1000: --- Train loss 0.040393 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 886 out of 1000: --- Train loss 0.040339 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 887 out of 1000: --- Train loss 0.040285 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 888 out of 1000: --- Train loss 0.040231 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 889 out of 1000: --- Train loss 0.040177 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 890 out of 1000: --- Train loss 0.040123 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 891 out of 1000: --- Train loss 0.040070 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 892 out of 1000: --- Train loss 0.040017 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 893 out of 1000: --- Train loss 0.039963 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 894 out of 1000: --- Train loss 0.039910 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 895 out of 1000: --- Train loss 0.039857 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 896 out of 1000: --- Train loss 0.039804 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 897 out of 1000: --- Train loss 0.039752 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 898 out of 1000: --- Train loss 0.039699 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 899 out of 1000: --- Train loss 0.039647 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 900 out of 1000: --- Train loss 0.039595 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 901 out of 1000: --- Train loss 0.039542 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 902 out of 1000: --- Train loss 0.039490 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 903 out of 1000: --- Train loss 0.039438 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 904 out of 1000: --- Train loss 0.039387 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 905 out of 1000: --- Train loss 0.039335 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 906 out of 1000: --- Train loss 0.039284 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 907 out of 1000: --- Train loss 0.039232 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 908 out of 1000: --- Train loss 0.039181 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909 out of 1000: --- Train loss 0.039130 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 910 out of 1000: --- Train loss 0.039079 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 911 out of 1000: --- Train loss 0.039028 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 912 out of 1000: --- Train loss 0.038977 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 913 out of 1000: --- Train loss 0.038926 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 914 out of 1000: --- Train loss 0.038876 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 915 out of 1000: --- Train loss 0.038825 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 916 out of 1000: --- Train loss 0.038775 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 917 out of 1000: --- Train loss 0.038725 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 918 out of 1000: --- Train loss 0.038675 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 919 out of 1000: --- Train loss 0.038625 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 920 out of 1000: --- Train loss 0.038575 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 921 out of 1000: --- Train loss 0.038526 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 922 out of 1000: --- Train loss 0.038476 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 923 out of 1000: --- Train loss 0.038427 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 924 out of 1000: --- Train loss 0.038377 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 925 out of 1000: --- Train loss 0.038328 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 926 out of 1000: --- Train loss 0.038279 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 927 out of 1000: --- Train loss 0.038230 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 928 out of 1000: --- Train loss 0.038181 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 929 out of 1000: --- Train loss 0.038133 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 930 out of 1000: --- Train loss 0.038084 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 931 out of 1000: --- Train loss 0.038036 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 932 out of 1000: --- Train loss 0.037987 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 933 out of 1000: --- Train loss 0.037939 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 934 out of 1000: --- Train loss 0.037891 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 935 out of 1000: --- Train loss 0.037843 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 936 out of 1000: --- Train loss 0.037795 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 937 out of 1000: --- Train loss 0.037747 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 938 out of 1000: --- Train loss 0.037699 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 939 out of 1000: --- Train loss 0.037652 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 940 out of 1000: --- Train loss 0.037604 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 941 out of 1000: --- Train loss 0.037557 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 942 out of 1000: --- Train loss 0.037510 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 943 out of 1000: --- Train loss 0.037463 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 944 out of 1000: --- Train loss 0.037416 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 945 out of 1000: --- Train loss 0.037369 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 946 out of 1000: --- Train loss 0.037322 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 947 out of 1000: --- Train loss 0.037275 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 948 out of 1000: --- Train loss 0.037229 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 949 out of 1000: --- Train loss 0.037182 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 950 out of 1000: --- Train loss 0.037136 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 951 out of 1000: --- Train loss 0.037090 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 952 out of 1000: --- Train loss 0.037044 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 953 out of 1000: --- Train loss 0.036998 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 954 out of 1000: --- Train loss 0.036952 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 955 out of 1000: --- Train loss 0.036906 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 956 out of 1000: --- Train loss 0.036860 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 957 out of 1000: --- Train loss 0.036815 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 958 out of 1000: --- Train loss 0.036769 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 959 out of 1000: --- Train loss 0.036724 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 960 out of 1000: --- Train loss 0.036679 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 961 out of 1000: --- Train loss 0.036633 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 962 out of 1000: --- Train loss 0.036588 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 963 out of 1000: --- Train loss 0.036543 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 964 out of 1000: --- Train loss 0.036498 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 965 out of 1000: --- Train loss 0.036454 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 966 out of 1000: --- Train loss 0.036409 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 967 out of 1000: --- Train loss 0.036365 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 968 out of 1000: --- Train loss 0.036320 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 969 out of 1000: --- Train loss 0.036276 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 970 out of 1000: --- Train loss 0.036232 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 971 out of 1000: --- Train loss 0.036187 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 972 out of 1000: --- Train loss 0.036143 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 973 out of 1000: --- Train loss 0.036099 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 974 out of 1000: --- Train loss 0.036056 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 975 out of 1000: --- Train loss 0.036012 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 976 out of 1000: --- Train loss 0.035968 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 977 out of 1000: --- Train loss 0.035925 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 978 out of 1000: --- Train loss 0.035881 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 979 out of 1000: --- Train loss 0.035838 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 980 out of 1000: --- Train loss 0.035795 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 981 out of 1000: --- Train loss 0.035752 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 982 out of 1000: --- Train loss 0.035709 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 983 out of 1000: --- Train loss 0.035666 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 984 out of 1000: --- Train loss 0.035623 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 985 out of 1000: --- Train loss 0.035580 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 986 out of 1000: --- Train loss 0.035537 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 987 out of 1000: --- Train loss 0.035495 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 988 out of 1000: --- Train loss 0.035452 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 989 out of 1000: --- Train loss 0.035410 --- Train accuracy 1.000000 --- valid f_score 0.333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990 out of 1000: --- Train loss 0.035368 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 991 out of 1000: --- Train loss 0.035326 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 992 out of 1000: --- Train loss 0.035284 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 993 out of 1000: --- Train loss 0.035242 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 994 out of 1000: --- Train loss 0.035200 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 995 out of 1000: --- Train loss 0.035158 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 996 out of 1000: --- Train loss 0.035116 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 997 out of 1000: --- Train loss 0.035075 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 998 out of 1000: --- Train loss 0.035033 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "Epoch 999 out of 1000: --- Train loss 0.034992 --- Train accuracy 1.000000 --- valid f_score 0.333333\n",
      "0.680407272939\n"
     ]
    }
   ],
   "source": [
    "validate_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting"
     ]
    }
   ],
   "source": [
    "score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
